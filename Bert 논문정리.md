BERT: Pre-trainig of Deep Bidirectional Transformers for Language Understanding
===============================================================================

해당 페이지의 구성은 논문을 쭉 읽어나가며 공부하고 정리한 포스트입니다.
-----------------------------------------------------------------


- BERT : Bidirectional Encoder Representations form Transformer


