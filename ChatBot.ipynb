{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JmUNOIjol8u6LibX5yEZR_XkJzRvGJKO","timestamp":1670423407656},{"file_id":"18u4tuZPeiHn7shIUYRj6ZdKuOyBUbe5L","timestamp":1670153378168},{"file_id":"1DKFUPzxhGWGB_ZoYgN_ikv4P4nYf25K4","timestamp":1669941198963}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"529d0bd240124ad0996beb37b84df0c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4409363d601444080dc231d66ac04f9","IPY_MODEL_2f1d96ea89f64c02859f552513f82569","IPY_MODEL_2009ae2d8659480ba38e2b52bd50b785"],"layout":"IPY_MODEL_99fd91bd21dc424cb125b8bf82103060"}},"a4409363d601444080dc231d66ac04f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2870d1f79d0a4c269b2013c5ae04207e","placeholder":"​","style":"IPY_MODEL_e18cd0870770401998906f5ae942656c","value":"Downloading: 100%"}},"2f1d96ea89f64c02859f552513f82569":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07485e67417a49d1b5991cc7dd93f9ad","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_796a8f17426d47b2a98f4c4b114449d9","value":2825034}},"2009ae2d8659480ba38e2b52bd50b785":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c974a4d736e4e0aa8fb2e1df8dfaeab","placeholder":"​","style":"IPY_MODEL_295f636c11ec4986ba5e6881d72dfd18","value":" 2.83M/2.83M [00:00&lt;00:00, 5.54MB/s]"}},"99fd91bd21dc424cb125b8bf82103060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2870d1f79d0a4c269b2013c5ae04207e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e18cd0870770401998906f5ae942656c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07485e67417a49d1b5991cc7dd93f9ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796a8f17426d47b2a98f4c4b114449d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c974a4d736e4e0aa8fb2e1df8dfaeab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"295f636c11ec4986ba5e6881d72dfd18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36ff5032b1794d7da83f50b83b6a1028":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be485e1609a8482b88f3df0e2f2a5b95","IPY_MODEL_ad1f4688080140b2a20cbf1f6181799e","IPY_MODEL_31502d43ca5a45d0b70dc48e0ced499b"],"layout":"IPY_MODEL_5365579db72b479f90d9685ecdc74147"}},"be485e1609a8482b88f3df0e2f2a5b95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7411adacb2f3470ab8263e0c06cefa82","placeholder":"​","style":"IPY_MODEL_0df0ccdf19e94451b4145bd87c5f69e8","value":"Downloading: 100%"}},"ad1f4688080140b2a20cbf1f6181799e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44e1d7882c7b42309ef68716b3e6196a","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03afb31c12ce4f16ae09aed113841922","value":1000}},"31502d43ca5a45d0b70dc48e0ced499b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f35e313cc3734264bfb68116284cda4d","placeholder":"​","style":"IPY_MODEL_7a3085ace50b4999b8484a02ee6d574b","value":" 1.00k/1.00k [00:00&lt;00:00, 40.8kB/s]"}},"5365579db72b479f90d9685ecdc74147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7411adacb2f3470ab8263e0c06cefa82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0df0ccdf19e94451b4145bd87c5f69e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44e1d7882c7b42309ef68716b3e6196a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03afb31c12ce4f16ae09aed113841922":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f35e313cc3734264bfb68116284cda4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a3085ace50b4999b8484a02ee6d574b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06731cf712ea4e1ca8102ef493ad3d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecdddbfa4053423c8144e3a9f6b87bf3","IPY_MODEL_f55b22ff46da49e2b9fd805bb3cd6cd3","IPY_MODEL_70caf097c22e4729a849c7bfea8d7c35"],"layout":"IPY_MODEL_349af36cef2c40329b54da9b5abf20be"}},"ecdddbfa4053423c8144e3a9f6b87bf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78309c57a9d448a5926233889db761e7","placeholder":"​","style":"IPY_MODEL_869107e0430f4568b223c5e319b85f3e","value":"Downloading: 100%"}},"f55b22ff46da49e2b9fd805bb3cd6cd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_595929dc195449c5b76c630716d07135","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e424ba393b9f44119c3d429ab82ce936","value":513302779}},"70caf097c22e4729a849c7bfea8d7c35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6a3ee1c1dbe42fdaae7a0d69d348f3d","placeholder":"​","style":"IPY_MODEL_088c7fe8517643c09348444dd8ac1a51","value":" 513M/513M [00:21&lt;00:00, 23.2MB/s]"}},"349af36cef2c40329b54da9b5abf20be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78309c57a9d448a5926233889db761e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869107e0430f4568b223c5e319b85f3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"595929dc195449c5b76c630716d07135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e424ba393b9f44119c3d429ab82ce936":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6a3ee1c1dbe42fdaae7a0d69d348f3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088c7fe8517643c09348444dd8ac1a51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# ag_train['num_len']=ag_train.Utterance.apply(lambda x:len(x))"],"metadata":{"id":"x_thQQeBJg3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop(ag_train[ag_train.num_len==1].index,inplace=True)"],"metadata":{"id":"JGxiLPuAGTdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trying=ag_train[(ag_train.num_len==3)&(ag_train.Target=='neutral')]['Utterance'].index"],"metadata":{"id":"vRrvT15DIaCh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"tgkaCEnMvKYC"}},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying1]=ag_train['Utterance'][(ag_train.num_len==4)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"q6coOTtla-oo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying2]=ag_train['Utterance'][(ag_train.num_len==5)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"nlDfluaZjeIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying3]=ag_train['Utterance'][(ag_train.num_len==6)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"BmOGcBpeu6cD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying4]=ag_train['Utterance'][(ag_train.num_len==7)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"m3NwwGue0Z9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying5]=ag_train['Utterance'][(ag_train.num_len<20)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOf758704rk-","executionInfo":{"status":"ok","timestamp":1670204786035,"user_tz":-540,"elapsed":554,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"e6017eb8-979d-47e9-e2c7-2cedb8a19981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["# ag_train.drop(ag_train[(ag_train.num_len==2)&(ag_train.Target!='neutral')].index,inplace=True)"],"metadata":{"id":"gl5kYKs-HtUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop(ag_train[(ag_train.num_len==3)&(ag_train.Target=='neutral')].index,inplace=True)"],"metadata":{"id":"L4d1dtrj3iB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop(ag_train[(ag_train.num_len>5)&(ag_train.Target=='neutral')].index,inplace=True)"],"metadata":{"id":"1pW4IKAa7svD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop('num_len',axis=1,inplace=True)"],"metadata":{"id":"auXNdM9fIdvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZcR5__j2mknU","executionInfo":{"status":"ok","timestamp":1670287344928,"user_tz":-540,"elapsed":3963,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"ccb240f1-24f2-4dca-ab23-b86a92072afb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n"]}]},{"cell_type":"code","source":["{\n","  \"nbformat\": 4,\n","  \"nbformat_minor\": 0,\n","  \"metadata\": {\n","    \"colab\": {\n","      \"provenance\": [],\n","      \"machine_shape\": \"hm\"\n","    },\n","    \"kernelspec\": {\n","      \"name\": \"python3\",\n","      \"display_name\": \"Python 3\"\n","    },\n","    \"language_info\": {\n","      \"name\": \"python\"\n","    },\n","    \"accelerator\": \"GPU\",\n","    \"gpuClass\": \"standard\"\n","  },\n","  \"cells\": [\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"!pip install transformers -q\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"Ax2iPY0JuKAC\"\n","      },\n","      \"execution_count\": 6,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"# 챗봇 데이터를 처리하는 클래스를 만든다.\\n\",\n","        \"class ChatbotDataset(Dataset):\\n\",\n","        \"    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\\n\",\n","        \"        self._data = chats\\n\",\n","        \"        self.max_len = max_len\\n\",\n","        \"        self.q_token = Q_TKN\\n\",\n","        \"        self.a_token = A_TKN\\n\",\n","        \"        self.sent_token = SENT\\n\",\n","        \"        self.eos = EOS\\n\",\n","        \"        self.mask = MASK\\n\",\n","        \"        self.tokenizer = koGPT2_TOKENIZER\\n\",\n","        \"\\n\",\n","        \"    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\\n\",\n","        \"        return len(self._data)\\n\",\n","        \"\\n\",\n","        \"    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\\n\",\n","        \"        turn = self._data.iloc[idx]\\n\",\n","        \"        q = turn[\\\"Q\\\"]  # 질문을 가져온다.\\n\",\n","        \"        q = re.sub(r\\\"([?.!,])\\\", r\\\" \\\", q)  # 구둣점들을 제거한다.\\n\",\n","        \"\\n\",\n","        \"        a = turn[\\\"A\\\"]  # 답변을 가져온다.\\n\",\n","        \"        a = re.sub(r\\\"([?.!,])\\\", r\\\" \\\", a)  # 구둣점들을 제거한다.\\n\",\n","        \"\\n\",\n","        \"        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\\n\",\n","        \"        q_len = len(q_toked)\\n\",\n","        \"\\n\",\n","        \"        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\\n\",\n","        \"        a_len = len(a_toked)\\n\",\n","        \"\\n\",\n","        \"        #질문의 길이가 최대길이보다 크면\\n\",\n","        \"        if q_len > self.max_len:\\n\",\n","        \"            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\\n\",\n","        \"            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\\n\",\n","        \"                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \\n\",\n","        \"                q_len = len(q_toked)\\n\",\n","        \"                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\\n\",\n","        \"            a_toked = a_toked[:a_len]\\n\",\n","        \"            a_len = len(a_toked)\\n\",\n","        \"\\n\",\n","        \"        #질문의 길이 + 답변의 길이가 최대길이보다 크면\\n\",\n","        \"        if q_len + a_len > self.max_len:\\n\",\n","        \"            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\\n\",\n","        \"            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\\n\",\n","        \"                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \\n\",\n","        \"                q_len = len(q_toked)\\n\",\n","        \"                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\\n\",\n","        \"            a_toked = a_toked[:a_len]\\n\",\n","        \"            a_len = len(a_toked)\\n\",\n","        \"\\n\",\n","        \"        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\\n\",\n","        \"        labels = [self.mask,] * q_len + a_toked[1:]\\n\",\n","        \"\\n\",\n","        \"        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\\n\",\n","        \"        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\\n\",\n","        \"        # 답변 labels을 index 로 만든다.\\n\",\n","        \"        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\\n\",\n","        \"        # 최대길이만큼 PADDING\\n\",\n","        \"        while len(labels_ids) < self.max_len:\\n\",\n","        \"            labels_ids += [self.tokenizer.pad_token_id]\\n\",\n","        \"\\n\",\n","        \"        # 질문 + 답변을 index 로 만든다.    \\n\",\n","        \"        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\\n\",\n","        \"        # 최대길이만큼 PADDING\\n\",\n","        \"        while len(token_ids) < self.max_len:\\n\",\n","        \"            token_ids += [self.tokenizer.pad_token_id]\\n\",\n","        \"\\n\",\n","        \"        #질문+답변, 마스크, 답변\\n\",\n","        \"        return (token_ids, np.array(mask), labels_ids)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"wtSydcC3uJq0\"\n","      },\n","      \"execution_count\": 7,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"def collate_batch(batch):\\n\",\n","        \"    data = [item[0] for item in batch]\\n\",\n","        \"    mask = [item[1] for item in batch]\\n\",\n","        \"    label = [item[2] for item in batch]\\n\",\n","        \"    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"7Eo3Lg5AuJuC\"\n","      },\n","      \"execution_count\": 9,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n\",\n","        \"\\n\",\n","        \"#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\\n\",\n","        \"train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"HflM0VSJudYO\"\n","      },\n","      \"execution_count\": 23,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"import torch\\n\",\n","        \"from transformers import GPT2LMHeadModel\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"CxDjdgREvEjO\"\n","      },\n","      \"execution_count\": 15,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"from transformers import PreTrainedTokenizerFast\\n\",\n","        \"tokenizer = PreTrainedTokenizerFast.from_pretrained(\\\"skt/kogpt2-base-v2\\\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \\n\",\n","        \"tokenizer.tokenize(\\\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\\\")\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"HGMBg0oWvEmG\",\n","        \"outputId\": \"b83b9538-220c-41b9-a85a-091cd09606cd\"\n","      },\n","      \"execution_count\": 16,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stderr\",\n","          \"text\": [\n","            \"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n\",\n","            \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","            \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"\n","          ]\n","        },\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"['▁안녕',\\n\",\n","              \" '하',\\n\",\n","              \" '세',\\n\",\n","              \" '요.',\\n\",\n","              \" '▁한국어',\\n\",\n","              \" '▁G',\\n\",\n","              \" 'P',\\n\",\n","              \" 'T',\\n\",\n","              \" '-2',\\n\",\n","              \" '▁입',\\n\",\n","              \" '니다.',\\n\",\n","              \" '😤',\\n\",\n","              \" ':)',\\n\",\n","              \" 'l^o']\"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 16\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"!pip install pytorch_lightning -q\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"GcszoiwMvX4Y\",\n","        \"outputId\": \"bf18fa61-232b-4fb0-c6d7-6325f673171d\"\n","      },\n","      \"execution_count\": 1,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stdout\",\n","          \"text\": [\n","            \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n","            \"Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.8.3.post1)\\n\",\n","            \"Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\\n\",\n","            \"Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.1.1)\\n\",\n","            \"Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\\n\",\n","            \"Requirement already satisfied: lightning-utilities==0.3.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.3.0)\\n\",\n","            \"Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\\n\",\n","            \"Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.1+cu113)\\n\",\n","            \"Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.0)\\n\",\n","            \"Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.5.1)\\n\",\n","            \"Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\\n\",\n","            \"Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\\n\",\n","            \"Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (from lightning-utilities==0.3.*->pytorch_lightning) (0.4.0)\\n\",\n","            \"Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\\n\",\n","            \"Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\\n\",\n","            \"Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\\n\",\n","            \"Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\\n\",\n","            \"Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\\n\",\n","            \"Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\\n\",\n","            \"Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\\n\",\n","            \"Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\\n\",\n","            \"Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\\n\",\n","            \"Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\\n\",\n","            \"Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\\n\",\n","            \"Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\\n\",\n","            \"Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\\n\",\n","            \"Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.15.0)\\n\",\n","            \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\\n\",\n","            \"Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\\n\",\n","            \"Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\\n\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"import numpy as np\\n\",\n","        \"import pandas as pd\\n\",\n","        \"import torch\\n\",\n","        \"from pytorch_lightning import Trainer\\n\",\n","        \"from pytorch_lightning.callbacks import ModelCheckpoint\\n\",\n","        \"from pytorch_lightning.core.lightning import LightningModule\\n\",\n","        \"from torch.utils.data import DataLoader, Dataset\\n\",\n","        \"from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\\n\",\n","        \"from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\\n\",\n","        \"import re\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"GKeLSiYmvExD\"\n","      },\n","      \"execution_count\": 28,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"Q_TKN = \\\"<usr>\\\"\\n\",\n","        \"A_TKN = \\\"<sys>\\\"\\n\",\n","        \"BOS = '</s>'\\n\",\n","        \"EOS = '</s>'\\n\",\n","        \"MASK = '<unused0>'\\n\",\n","        \"SENT = '<unused1>'\\n\",\n","        \"PAD = '<pad>'\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"6uciWc48vEzr\"\n","      },\n","      \"execution_count\": 29,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\\\"skt/kogpt2-base-v2\\\",\\n\",\n","        \"            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\\n\",\n","        \"            pad_token=PAD, mask_token=MASK) \\n\",\n","        \"model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"9by9OEqrvE2K\",\n","        \"outputId\": \"b49002e4-4f6d-48c1-9052-831070ac0117\"\n","      },\n","      \"execution_count\": 30,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stderr\",\n","          \"text\": [\n","            \"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n\",\n","            \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","            \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"import urllib.request\\n\",\n","        \"\\n\",\n","        \"urllib.request.urlretrieve(\\n\",\n","        \"    \\\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\\\",\\n\",\n","        \"    filename=\\\"ChatBotData.csv\\\",\\n\",\n","        \")\\n\",\n","        \"Chatbot_Data = pd.read_csv(\\\"ChatBotData.csv\\\")\\n\",\n","        \"# Test 용으로 300개 데이터만 처리한다.\\n\",\n","        \"Chatbot_Data = Chatbot_Data[:300]\\n\",\n","        \"Chatbot_Data.head()\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\",\n","          \"height\": 206\n","        },\n","        \"id\": \"riP0GLx7vE4f\",\n","        \"outputId\": \"c44e7367-4948-4def-bc8d-b6f4c54cb685\"\n","      },\n","      \"execution_count\": 31,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"                 Q            A  label\\n\",\n","              \"0           12시 땡!   하루가 또 가네요.      0\\n\",\n","              \"1      1지망 학교 떨어졌어    위로해 드립니다.      0\\n\",\n","              \"2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\\n\",\n","              \"3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\\n\",\n","              \"4          PPL 심하네   눈살이 찌푸려지죠.      0\"\n","            ],\n","            \"text/html\": [\n","              \"\\n\",\n","              \"  <div id=\\\"df-6907237d-e6c5-4927-95da-536fb96e400b\\\">\\n\",\n","              \"    <div class=\\\"colab-df-container\\\">\\n\",\n","              \"      <div>\\n\",\n","              \"<style scoped>\\n\",\n","              \"    .dataframe tbody tr th:only-of-type {\\n\",\n","              \"        vertical-align: middle;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .dataframe tbody tr th {\\n\",\n","              \"        vertical-align: top;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .dataframe thead th {\\n\",\n","              \"        text-align: right;\\n\",\n","              \"    }\\n\",\n","              \"</style>\\n\",\n","              \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n","              \"  <thead>\\n\",\n","              \"    <tr style=\\\"text-align: right;\\\">\\n\",\n","              \"      <th></th>\\n\",\n","              \"      <th>Q</th>\\n\",\n","              \"      <th>A</th>\\n\",\n","              \"      <th>label</th>\\n\",\n","              \"    </tr>\\n\",\n","              \"  </thead>\\n\",\n","              \"  <tbody>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>0</th>\\n\",\n","              \"      <td>12시 땡!</td>\\n\",\n","              \"      <td>하루가 또 가네요.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>1</th>\\n\",\n","              \"      <td>1지망 학교 떨어졌어</td>\\n\",\n","              \"      <td>위로해 드립니다.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>2</th>\\n\",\n","              \"      <td>3박4일 놀러가고 싶다</td>\\n\",\n","              \"      <td>여행은 언제나 좋죠.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>3</th>\\n\",\n","              \"      <td>3박4일 정도 놀러가고 싶다</td>\\n\",\n","              \"      <td>여행은 언제나 좋죠.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>4</th>\\n\",\n","              \"      <td>PPL 심하네</td>\\n\",\n","              \"      <td>눈살이 찌푸려지죠.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"  </tbody>\\n\",\n","              \"</table>\\n\",\n","              \"</div>\\n\",\n","              \"      <button class=\\\"colab-df-convert\\\" onclick=\\\"convertToInteractive('df-6907237d-e6c5-4927-95da-536fb96e400b')\\\"\\n\",\n","              \"              title=\\\"Convert this dataframe to an interactive table.\\\"\\n\",\n","              \"              style=\\\"display:none;\\\">\\n\",\n","              \"        \\n\",\n","              \"  <svg xmlns=\\\"http://www.w3.org/2000/svg\\\" height=\\\"24px\\\"viewBox=\\\"0 0 24 24\\\"\\n\",\n","              \"       width=\\\"24px\\\">\\n\",\n","              \"    <path d=\\\"M0 0h24v24H0V0z\\\" fill=\\\"none\\\"/>\\n\",\n","              \"    <path d=\\\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\\\"/><path d=\\\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\\\"/>\\n\",\n","              \"  </svg>\\n\",\n","              \"      </button>\\n\",\n","              \"      \\n\",\n","              \"  <style>\\n\",\n","              \"    .colab-df-container {\\n\",\n","              \"      display:flex;\\n\",\n","              \"      flex-wrap:wrap;\\n\",\n","              \"      gap: 12px;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .colab-df-convert {\\n\",\n","              \"      background-color: #E8F0FE;\\n\",\n","              \"      border: none;\\n\",\n","              \"      border-radius: 50%;\\n\",\n","              \"      cursor: pointer;\\n\",\n","              \"      display: none;\\n\",\n","              \"      fill: #1967D2;\\n\",\n","              \"      height: 32px;\\n\",\n","              \"      padding: 0 0 0 0;\\n\",\n","              \"      width: 32px;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .colab-df-convert:hover {\\n\",\n","              \"      background-color: #E2EBFA;\\n\",\n","              \"      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\\n\",\n","              \"      fill: #174EA6;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    [theme=dark] .colab-df-convert {\\n\",\n","              \"      background-color: #3B4455;\\n\",\n","              \"      fill: #D2E3FC;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    [theme=dark] .colab-df-convert:hover {\\n\",\n","              \"      background-color: #434B5C;\\n\",\n","              \"      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\\n\",\n","              \"      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\\n\",\n","              \"      fill: #FFFFFF;\\n\",\n","              \"    }\\n\",\n","              \"  </style>\\n\",\n","              \"\\n\",\n","              \"      <script>\\n\",\n","              \"        const buttonEl =\\n\",\n","              \"          document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b button.colab-df-convert');\\n\",\n","              \"        buttonEl.style.display =\\n\",\n","              \"          google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n","              \"\\n\",\n","              \"        async function convertToInteractive(key) {\\n\",\n","              \"          const element = document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b');\\n\",\n","              \"          const dataTable =\\n\",\n","              \"            await google.colab.kernel.invokeFunction('convertToInteractive',\\n\",\n","              \"                                                     [key], {});\\n\",\n","              \"          if (!dataTable) return;\\n\",\n","              \"\\n\",\n","              \"          const docLinkHtml = 'Like what you see? Visit the ' +\\n\",\n","              \"            '<a target=\\\"_blank\\\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\\n\",\n","              \"            + ' to learn more about interactive tables.';\\n\",\n","              \"          element.innerHTML = '';\\n\",\n","              \"          dataTable['output_type'] = 'display_data';\\n\",\n","              \"          await google.colab.output.renderOutput(dataTable, element);\\n\",\n","              \"          const docLink = document.createElement('div');\\n\",\n","              \"          docLink.innerHTML = docLinkHtml;\\n\",\n","              \"          element.appendChild(docLink);\\n\",\n","              \"        }\\n\",\n","              \"      </script>\\n\",\n","              \"    </div>\\n\",\n","              \"  </div>\\n\",\n","              \"  \"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 31\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        # \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n","        \"train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n\",\n","        \"#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\\n\",\n","        \"train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"h8VN4b7MvE62\"\n","      },\n","      \"execution_count\": 32,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"model.to(device,dtype=torch.float64)\\n\",\n","        \"model.train()\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"3eHHvpkBvE9D\",\n","        \"outputId\": \"2547619f-4af3-4562-f940-0182371b8773\"\n","      },\n","      \"execution_count\": 35,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"GPT2LMHeadModel(\\n\",\n","              \"  (transformer): GPT2Model(\\n\",\n","              \"    (wte): Embedding(51200, 768)\\n\",\n","              \"    (wpe): Embedding(1024, 768)\\n\",\n","              \"    (drop): Dropout(p=0.1, inplace=False)\\n\",\n","              \"    (h): ModuleList(\\n\",\n","              \"      (0): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (1): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (2): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (3): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (4): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (5): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (6): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (7): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (8): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (9): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (10): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (11): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"    )\\n\",\n","              \"    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"  )\\n\",\n","              \"  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\\n\",\n","              \")\"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 35\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"learning_rate = 3e-5\\n\",\n","        \"criterion = torch.nn.CrossEntropyLoss(reduction=\\\"none\\\")\\n\",\n","        \"optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n\",\n","        \"\\n\",\n","        \"epoch = 10\\n\",\n","        \"Sneg = -1e18\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"KVXEFddFvtpc\"\n","      },\n","      \"execution_count\": 36,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"print (\\\"start\\\")\\n\",\n","        \"for epoch in range(epoch):\\n\",\n","        \"    for batch_idx, samples in enumerate(train_dataloader):\\n\",\n","        \"        optimizer.zero_grad()\\n\",\n","        \"        token_ids, mask, label = samples\\n\",\n","        \"        out = model(token_ids).cuda()\\n\",\n","        \"        out = out.logits      #Returns a new tensor with the logit of the elements of input\\n\",\n","        \"        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\\n\",\n","        \"        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\\n\",\n","        \"        loss = criterion(mask_out.transpose(2, 1), label)\\n\",\n","        \"        # 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\\n\",\n","        \"        avg_loss = loss.sum() / mask.sum()\\n\",\n","        \"        avg_loss.backward()\\n\",\n","        \"        # 학습 끝\\n\",\n","        \"        optimizer.step()\\n\",\n","        \"print (\\\"end\\\")\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"4io3v7Puvtm-\",\n","        \"outputId\": \"2c99559f-497e-4b0a-e899-c75560364c91\"\n","      },\n","      \"execution_count\": 39,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stdout\",\n","          \"text\": [\n","            \"start\\n\",\n","            \"end\\n\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"with torch.no_grad():\\n\",\n","        \"    while 1:\\n\",\n","        \"        q = input(\\\"user > \\\").strip()\\n\",\n","        \"        if q == \\\"quit\\\":\\n\",\n","        \"            break\\n\",\n","        \"        a = \\\"\\\"\\n\",\n","        \"        while 1:\\n\",\n","        \"            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q  + A_TKN + a)).unsqueeze(dim=0)\\n\",\n","        \"            pred = model(input_ids).cuda()\\n\",\n","        \"            pred = pred.logits\\n\",\n","        \"            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\\n\",\n","        \"            if gen == EOS:\\n\",\n","        \"                break\\n\",\n","        \"            a += gen.replace(\\\"▁\\\", \\\" \\\")\\n\",\n","        \"        print(\\\"Chatbot > {}\\\".format(a.strip()))\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\",\n","          \"height\": 425\n","        },\n","        \"id\": \"85g8g8ZixeU8\",\n","        \"outputId\": \"16e51a16-e647-4b44-e217-2c0aa5c54215\"\n","      },\n","      \"execution_count\": 40,\n","      \"outputs\": [\n","        {\n","          \"name\": \"stdout\",\n","          \"output_type\": \"stream\",\n","          \"text\": [\n","            \"user > 안녕하세요\\n\"\n","          ]\n","        },\n","        {\n","          \"output_type\": \"error\",\n","          \"ename\": \"RuntimeError\",\n","          \"evalue\": \"ignored\",\n","          \"traceback\": [\n","            \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n","            \"\\u001b[0;31mRuntimeError\\u001b[0m                              Traceback (most recent call last)\",\n","            \"\\u001b[0;32m<ipython-input-40-75429edffc48>\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m\\u001b[0m\\n\\u001b[1;32m      7\\u001b[0m         \\u001b[0;32mwhile\\u001b[0m \\u001b[0;36m1\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      8\\u001b[0m             \\u001b[0minput_ids\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mtorch\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mLongTensor\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkoGPT2_TOKENIZER\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mencode\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mQ_TKN\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0mq\\u001b[0m  \\u001b[0;34m+\\u001b[0m \\u001b[0mA_TKN\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0ma\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0munsqueeze\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mdim\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;36m0\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 9\\u001b[0;31m             \\u001b[0mpred\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mmodel\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0minput_ids\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     10\\u001b[0m             \\u001b[0mpred\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mpred\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mlogits\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     11\\u001b[0m             \\u001b[0mgen\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mkoGPT2_TOKENIZER\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mconvert_ids_to_tokens\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mtorch\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0margmax\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mpred\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mdim\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;34m-\\u001b[0m\\u001b[0;36m1\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msqueeze\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mnumpy\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mtolist\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m-\\u001b[0m\\u001b[0;36m1\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\u001b[0m in \\u001b[0;36m_call_impl\\u001b[0;34m(self, *input, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1128\\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\u001b[1;32m   1129\\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\u001b[0;32m-> 1130\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mforward_call\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1131\\u001b[0m         \\u001b[0;31m# Do not call functions when jit is used\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1132\\u001b[0m         \\u001b[0mfull_backward_hooks\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnon_full_backward_hooks\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\u001b[0m in \\u001b[0;36mforward\\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\\u001b[0m\\n\\u001b[1;32m   1044\\u001b[0m         \\u001b[0mreturn_dict\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mreturn_dict\\u001b[0m \\u001b[0;32mif\\u001b[0m \\u001b[0mreturn_dict\\u001b[0m \\u001b[0;32mis\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0;32mNone\\u001b[0m \\u001b[0;32melse\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mconfig\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0muse_return_dict\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1045\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1046\\u001b[0;31m         transformer_outputs = self.transformer(\\n\\u001b[0m\\u001b[1;32m   1047\\u001b[0m             \\u001b[0minput_ids\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1048\\u001b[0m             \\u001b[0mpast_key_values\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mpast_key_values\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\u001b[0m in \\u001b[0;36m_call_impl\\u001b[0;34m(self, *input, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1128\\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\u001b[1;32m   1129\\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\u001b[0;32m-> 1130\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mforward_call\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1131\\u001b[0m         \\u001b[0;31m# Do not call functions when jit is used\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1132\\u001b[0m         \\u001b[0mfull_backward_hooks\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnon_full_backward_hooks\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\u001b[0m in \\u001b[0;36mforward\\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\\u001b[0m\\n\\u001b[1;32m    830\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    831\\u001b[0m         \\u001b[0;32mif\\u001b[0m \\u001b[0minputs_embeds\\u001b[0m \\u001b[0;32mis\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 832\\u001b[0;31m             \\u001b[0minputs_embeds\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mwte\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0minput_ids\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    833\\u001b[0m         \\u001b[0mposition_embeds\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mwpe\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mposition_ids\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    834\\u001b[0m         \\u001b[0mhidden_states\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0minputs_embeds\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0mposition_embeds\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\u001b[0m in \\u001b[0;36m_call_impl\\u001b[0;34m(self, *input, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1128\\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\u001b[1;32m   1129\\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\u001b[0;32m-> 1130\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mforward_call\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1131\\u001b[0m         \\u001b[0;31m# Do not call functions when jit is used\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1132\\u001b[0m         \\u001b[0mfull_backward_hooks\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnon_full_backward_hooks\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\\u001b[0m in \\u001b[0;36mforward\\u001b[0;34m(self, input)\\u001b[0m\\n\\u001b[1;32m    156\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    157\\u001b[0m     \\u001b[0;32mdef\\u001b[0m \\u001b[0mforward\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0minput\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0mTensor\\u001b[0m\\u001b[0;34m)\\u001b[0m \\u001b[0;34m->\\u001b[0m \\u001b[0mTensor\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 158\\u001b[0;31m         return F.embedding(\\n\\u001b[0m\\u001b[1;32m    159\\u001b[0m             \\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mweight\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpadding_idx\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmax_norm\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    160\\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\\u001b[0m in \\u001b[0;36membedding\\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\\u001b[0m\\n\\u001b[1;32m   2197\\u001b[0m         \\u001b[0;31m# remove once script supports set_grad_enabled\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2198\\u001b[0m         \\u001b[0m_no_grad_embedding_renorm_\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mweight\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mmax_norm\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnorm_type\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 2199\\u001b[0;31m     \\u001b[0;32mreturn\\u001b[0m \\u001b[0mtorch\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0membedding\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mweight\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mpadding_idx\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mscale_grad_by_freq\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0msparse\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   2200\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2201\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;31mRuntimeError\\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"QO5VC8WLyThv\",\n","        \"outputId\": \"169e4e53-4475-4c42-b58b-1b7b8263e59e\"\n","      },\n","      \"execution_count\": 38,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"True\"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 38\n","        }\n","      ]\n","    }\n","  ]\n","}"],"metadata":{"id":"0EBG5PNfpS8B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670390521076,"user_tz":-540,"elapsed":328,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"ced7ac32-6b19-49c0-9056-6093d1c7062a"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'nbformat': 4,\n"," 'nbformat_minor': 0,\n"," 'metadata': {'colab': {'provenance': [], 'machine_shape': 'hm'},\n","  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n","  'language_info': {'name': 'python'},\n","  'accelerator': 'GPU',\n","  'gpuClass': 'standard'},\n"," 'cells': [{'cell_type': 'code',\n","   'source': ['!pip install transformers -q'],\n","   'metadata': {'id': 'Ax2iPY0JuKAC'},\n","   'execution_count': 6,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['# 챗봇 데이터를 처리하는 클래스를 만든다.\\n',\n","    'class ChatbotDataset(Dataset):\\n',\n","    '    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\\n',\n","    '        self._data = chats\\n',\n","    '        self.max_len = max_len\\n',\n","    '        self.q_token = Q_TKN\\n',\n","    '        self.a_token = A_TKN\\n',\n","    '        self.sent_token = SENT\\n',\n","    '        self.eos = EOS\\n',\n","    '        self.mask = MASK\\n',\n","    '        self.tokenizer = koGPT2_TOKENIZER\\n',\n","    '\\n',\n","    '    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\\n',\n","    '        return len(self._data)\\n',\n","    '\\n',\n","    '    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\\n',\n","    '        turn = self._data.iloc[idx]\\n',\n","    '        q = turn[\"Q\"]  # 질문을 가져온다.\\n',\n","    '        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\\n',\n","    '\\n',\n","    '        a = turn[\"A\"]  # 답변을 가져온다.\\n',\n","    '        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\\n',\n","    '\\n',\n","    '        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\\n',\n","    '        q_len = len(q_toked)\\n',\n","    '\\n',\n","    '        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\\n',\n","    '        a_len = len(a_toked)\\n',\n","    '\\n',\n","    '        #질문의 길이가 최대길이보다 크면\\n',\n","    '        if q_len > self.max_len:\\n',\n","    '            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\\n',\n","    '            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\\n',\n","    '                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \\n',\n","    '                q_len = len(q_toked)\\n',\n","    '                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\\n',\n","    '            a_toked = a_toked[:a_len]\\n',\n","    '            a_len = len(a_toked)\\n',\n","    '\\n',\n","    '        #질문의 길이 + 답변의 길이가 최대길이보다 크면\\n',\n","    '        if q_len + a_len > self.max_len:\\n',\n","    '            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\\n',\n","    '            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\\n',\n","    '                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \\n',\n","    '                q_len = len(q_toked)\\n',\n","    '                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\\n',\n","    '            a_toked = a_toked[:a_len]\\n',\n","    '            a_len = len(a_toked)\\n',\n","    '\\n',\n","    '        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\\n',\n","    '        labels = [self.mask,] * q_len + a_toked[1:]\\n',\n","    '\\n',\n","    '        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\\n',\n","    '        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\\n',\n","    '        # 답변 labels을 index 로 만든다.\\n',\n","    '        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\\n',\n","    '        # 최대길이만큼 PADDING\\n',\n","    '        while len(labels_ids) < self.max_len:\\n',\n","    '            labels_ids += [self.tokenizer.pad_token_id]\\n',\n","    '\\n',\n","    '        # 질문 + 답변을 index 로 만든다.    \\n',\n","    '        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\\n',\n","    '        # 최대길이만큼 PADDING\\n',\n","    '        while len(token_ids) < self.max_len:\\n',\n","    '            token_ids += [self.tokenizer.pad_token_id]\\n',\n","    '\\n',\n","    '        #질문+답변, 마스크, 답변\\n',\n","    '        return (token_ids, np.array(mask), labels_ids)'],\n","   'metadata': {'id': 'wtSydcC3uJq0'},\n","   'execution_count': 7,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['def collate_batch(batch):\\n',\n","    '    data = [item[0] for item in batch]\\n',\n","    '    mask = [item[1] for item in batch]\\n',\n","    '    label = [item[2] for item in batch]\\n',\n","    '    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)'],\n","   'metadata': {'id': '7Eo3Lg5AuJuC'},\n","   'execution_count': 9,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n',\n","    '\\n',\n","    '#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\\n',\n","    'train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)'],\n","   'metadata': {'id': 'HflM0VSJudYO'},\n","   'execution_count': 23,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['import torch\\n', 'from transformers import GPT2LMHeadModel'],\n","   'metadata': {'id': 'CxDjdgREvEjO'},\n","   'execution_count': 15,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['from transformers import PreTrainedTokenizerFast\\n',\n","    'tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token=\\'</s>\\', eos_token=\\'</s>\\', unk_token=\\'<unk>\\', pad_token=\\'<pad>\\', mask_token=\\'<mask>\\') \\n',\n","    'tokenizer.tokenize(\"안녕하세요. 한국어 GPT-2 입니다.😤:)l^o\")'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': 'HGMBg0oWvEmG',\n","    'outputId': 'b83b9538-220c-41b9-a85a-091cd09606cd'},\n","   'execution_count': 16,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stderr',\n","     'text': ['The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n',\n","      \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","      \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"]},\n","    {'output_type': 'execute_result',\n","     'data': {'text/plain': [\"['▁안녕',\\n\",\n","       \" '하',\\n\",\n","       \" '세',\\n\",\n","       \" '요.',\\n\",\n","       \" '▁한국어',\\n\",\n","       \" '▁G',\\n\",\n","       \" 'P',\\n\",\n","       \" 'T',\\n\",\n","       \" '-2',\\n\",\n","       \" '▁입',\\n\",\n","       \" '니다.',\\n\",\n","       \" '😤',\\n\",\n","       \" ':)',\\n\",\n","       \" 'l^o']\"]},\n","     'metadata': {},\n","     'execution_count': 16}]},\n","  {'cell_type': 'code',\n","   'source': ['!pip install pytorch_lightning -q'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': 'GcszoiwMvX4Y',\n","    'outputId': 'bf18fa61-232b-4fb0-c6d7-6325f673171d'},\n","   'execution_count': 1,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stdout',\n","     'text': ['Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n',\n","      'Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.8.3.post1)\\n',\n","      'Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\\n',\n","      'Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.1.1)\\n',\n","      'Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\\n',\n","      'Requirement already satisfied: lightning-utilities==0.3.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.3.0)\\n',\n","      'Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\\n',\n","      'Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.1+cu113)\\n',\n","      'Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.0)\\n',\n","      'Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.5.1)\\n',\n","      'Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\\n',\n","      'Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\\n',\n","      'Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (from lightning-utilities==0.3.*->pytorch_lightning) (0.4.0)\\n',\n","      'Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\\n',\n","      'Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\\n',\n","      'Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\\n',\n","      'Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\\n',\n","      'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\\n',\n","      'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\\n',\n","      'Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\\n',\n","      'Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\\n',\n","      'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\\n',\n","      'Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\\n',\n","      'Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\\n',\n","      'Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\\n',\n","      'Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\\n',\n","      'Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.15.0)\\n',\n","      'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\\n',\n","      'Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\\n',\n","      'Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\\n']}]},\n","  {'cell_type': 'code',\n","   'source': ['import numpy as np\\n',\n","    'import pandas as pd\\n',\n","    'import torch\\n',\n","    'from pytorch_lightning import Trainer\\n',\n","    'from pytorch_lightning.callbacks import ModelCheckpoint\\n',\n","    'from pytorch_lightning.core.lightning import LightningModule\\n',\n","    'from torch.utils.data import DataLoader, Dataset\\n',\n","    'from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\\n',\n","    'from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\\n',\n","    'import re'],\n","   'metadata': {'id': 'GKeLSiYmvExD'},\n","   'execution_count': 28,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['Q_TKN = \"<usr>\"\\n',\n","    'A_TKN = \"<sys>\"\\n',\n","    \"BOS = '</s>'\\n\",\n","    \"EOS = '</s>'\\n\",\n","    \"MASK = '<unused0>'\\n\",\n","    \"SENT = '<unused1>'\\n\",\n","    \"PAD = '<pad>'\"],\n","   'metadata': {'id': '6uciWc48vEzr'},\n","   'execution_count': 29,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\\n',\n","    \"            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\\n\",\n","    '            pad_token=PAD, mask_token=MASK) \\n',\n","    \"model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\"],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': '9by9OEqrvE2K',\n","    'outputId': 'b49002e4-4f6d-48c1-9052-831070ac0117'},\n","   'execution_count': 30,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stderr',\n","     'text': ['The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n',\n","      \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","      \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"]}]},\n","  {'cell_type': 'code',\n","   'source': ['import urllib.request\\n',\n","    '\\n',\n","    'urllib.request.urlretrieve(\\n',\n","    '    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\\n',\n","    '    filename=\"ChatBotData.csv\",\\n',\n","    ')\\n',\n","    'Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\\n',\n","    '# Test 용으로 300개 데이터만 처리한다.\\n',\n","    'Chatbot_Data = Chatbot_Data[:300]\\n',\n","    'Chatbot_Data.head()'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/',\n","     'height': 206},\n","    'id': 'riP0GLx7vE4f',\n","    'outputId': 'c44e7367-4948-4def-bc8d-b6f4c54cb685'},\n","   'execution_count': 31,\n","   'outputs': [{'output_type': 'execute_result',\n","     'data': {'text/plain': ['                 Q            A  label\\n',\n","       '0           12시 땡!   하루가 또 가네요.      0\\n',\n","       '1      1지망 학교 떨어졌어    위로해 드립니다.      0\\n',\n","       '2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\\n',\n","       '3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\\n',\n","       '4          PPL 심하네   눈살이 찌푸려지죠.      0'],\n","      'text/html': ['\\n',\n","       '  <div id=\"df-6907237d-e6c5-4927-95da-536fb96e400b\">\\n',\n","       '    <div class=\"colab-df-container\">\\n',\n","       '      <div>\\n',\n","       '<style scoped>\\n',\n","       '    .dataframe tbody tr th:only-of-type {\\n',\n","       '        vertical-align: middle;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .dataframe tbody tr th {\\n',\n","       '        vertical-align: top;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .dataframe thead th {\\n',\n","       '        text-align: right;\\n',\n","       '    }\\n',\n","       '</style>\\n',\n","       '<table border=\"1\" class=\"dataframe\">\\n',\n","       '  <thead>\\n',\n","       '    <tr style=\"text-align: right;\">\\n',\n","       '      <th></th>\\n',\n","       '      <th>Q</th>\\n',\n","       '      <th>A</th>\\n',\n","       '      <th>label</th>\\n',\n","       '    </tr>\\n',\n","       '  </thead>\\n',\n","       '  <tbody>\\n',\n","       '    <tr>\\n',\n","       '      <th>0</th>\\n',\n","       '      <td>12시 땡!</td>\\n',\n","       '      <td>하루가 또 가네요.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>1</th>\\n',\n","       '      <td>1지망 학교 떨어졌어</td>\\n',\n","       '      <td>위로해 드립니다.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>2</th>\\n',\n","       '      <td>3박4일 놀러가고 싶다</td>\\n',\n","       '      <td>여행은 언제나 좋죠.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>3</th>\\n',\n","       '      <td>3박4일 정도 놀러가고 싶다</td>\\n',\n","       '      <td>여행은 언제나 좋죠.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>4</th>\\n',\n","       '      <td>PPL 심하네</td>\\n',\n","       '      <td>눈살이 찌푸려지죠.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '  </tbody>\\n',\n","       '</table>\\n',\n","       '</div>\\n',\n","       '      <button class=\"colab-df-convert\" onclick=\"convertToInteractive(\\'df-6907237d-e6c5-4927-95da-536fb96e400b\\')\"\\n',\n","       '              title=\"Convert this dataframe to an interactive table.\"\\n',\n","       '              style=\"display:none;\">\\n',\n","       '        \\n',\n","       '  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\\n',\n","       '       width=\"24px\">\\n',\n","       '    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\\n',\n","       '    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\\n',\n","       '  </svg>\\n',\n","       '      </button>\\n',\n","       '      \\n',\n","       '  <style>\\n',\n","       '    .colab-df-container {\\n',\n","       '      display:flex;\\n',\n","       '      flex-wrap:wrap;\\n',\n","       '      gap: 12px;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .colab-df-convert {\\n',\n","       '      background-color: #E8F0FE;\\n',\n","       '      border: none;\\n',\n","       '      border-radius: 50%;\\n',\n","       '      cursor: pointer;\\n',\n","       '      display: none;\\n',\n","       '      fill: #1967D2;\\n',\n","       '      height: 32px;\\n',\n","       '      padding: 0 0 0 0;\\n',\n","       '      width: 32px;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .colab-df-convert:hover {\\n',\n","       '      background-color: #E2EBFA;\\n',\n","       '      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\\n',\n","       '      fill: #174EA6;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    [theme=dark] .colab-df-convert {\\n',\n","       '      background-color: #3B4455;\\n',\n","       '      fill: #D2E3FC;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    [theme=dark] .colab-df-convert:hover {\\n',\n","       '      background-color: #434B5C;\\n',\n","       '      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\\n',\n","       '      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\\n',\n","       '      fill: #FFFFFF;\\n',\n","       '    }\\n',\n","       '  </style>\\n',\n","       '\\n',\n","       '      <script>\\n',\n","       '        const buttonEl =\\n',\n","       \"          document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b button.colab-df-convert');\\n\",\n","       '        buttonEl.style.display =\\n',\n","       \"          google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n","       '\\n',\n","       '        async function convertToInteractive(key) {\\n',\n","       \"          const element = document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b');\\n\",\n","       '          const dataTable =\\n',\n","       \"            await google.colab.kernel.invokeFunction('convertToInteractive',\\n\",\n","       '                                                     [key], {});\\n',\n","       '          if (!dataTable) return;\\n',\n","       '\\n',\n","       \"          const docLinkHtml = 'Like what you see? Visit the ' +\\n\",\n","       '            \\'<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>\\'\\n',\n","       \"            + ' to learn more about interactive tables.';\\n\",\n","       \"          element.innerHTML = '';\\n\",\n","       \"          dataTable['output_type'] = 'display_data';\\n\",\n","       '          await google.colab.output.renderOutput(dataTable, element);\\n',\n","       \"          const docLink = document.createElement('div');\\n\",\n","       '          docLink.innerHTML = docLinkHtml;\\n',\n","       '          element.appendChild(docLink);\\n',\n","       '        }\\n',\n","       '      </script>\\n',\n","       '    </div>\\n',\n","       '  </div>\\n',\n","       '  ']},\n","     'metadata': {},\n","     'execution_count': 31}]},\n","  {'cell_type': 'code',\n","   'source': ['train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n',\n","    '#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\\n',\n","    'train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)'],\n","   'metadata': {'id': 'h8VN4b7MvE62'},\n","   'execution_count': 32,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['model.to(device,dtype=torch.float64)\\n', 'model.train()'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': '3eHHvpkBvE9D',\n","    'outputId': '2547619f-4af3-4562-f940-0182371b8773'},\n","   'execution_count': 35,\n","   'outputs': [{'output_type': 'execute_result',\n","     'data': {'text/plain': ['GPT2LMHeadModel(\\n',\n","       '  (transformer): GPT2Model(\\n',\n","       '    (wte): Embedding(51200, 768)\\n',\n","       '    (wpe): Embedding(1024, 768)\\n',\n","       '    (drop): Dropout(p=0.1, inplace=False)\\n',\n","       '    (h): ModuleList(\\n',\n","       '      (0): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (1): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (2): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (3): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (4): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (5): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (6): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (7): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (8): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (9): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (10): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (11): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '    )\\n',\n","       '    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '  )\\n',\n","       '  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\\n',\n","       ')']},\n","     'metadata': {},\n","     'execution_count': 35}]},\n","  {'cell_type': 'code',\n","   'source': ['learning_rate = 3e-5\\n',\n","    'criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\\n',\n","    'optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n',\n","    '\\n',\n","    'epoch = 10\\n',\n","    'Sneg = -1e18'],\n","   'metadata': {'id': 'KVXEFddFvtpc'},\n","   'execution_count': 36,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['print (\"start\")\\n',\n","    'for epoch in range(epoch):\\n',\n","    '    for batch_idx, samples in enumerate(train_dataloader):\\n',\n","    '        optimizer.zero_grad()\\n',\n","    '        token_ids, mask, label = samples\\n',\n","    '        out = model(token_ids).cuda()\\n',\n","    '        out = out.logits      #Returns a new tensor with the logit of the elements of input\\n',\n","    '        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\\n',\n","    '        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\\n',\n","    '        loss = criterion(mask_out.transpose(2, 1), label)\\n',\n","    '        # 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\\n',\n","    '        avg_loss = loss.sum() / mask.sum()\\n',\n","    '        avg_loss.backward()\\n',\n","    '        # 학습 끝\\n',\n","    '        optimizer.step()\\n',\n","    'print (\"end\")'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': '4io3v7Puvtm-',\n","    'outputId': '2c99559f-497e-4b0a-e899-c75560364c91'},\n","   'execution_count': 39,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stdout',\n","     'text': ['start\\n', 'end\\n']}]},\n","  {'cell_type': 'code',\n","   'source': ['with torch.no_grad():\\n',\n","    '    while 1:\\n',\n","    '        q = input(\"user > \").strip()\\n',\n","    '        if q == \"quit\":\\n',\n","    '            break\\n',\n","    '        a = \"\"\\n',\n","    '        while 1:\\n',\n","    '            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q  + A_TKN + a)).unsqueeze(dim=0)\\n',\n","    '            pred = model(input_ids).cuda()\\n',\n","    '            pred = pred.logits\\n',\n","    '            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\\n',\n","    '            if gen == EOS:\\n',\n","    '                break\\n',\n","    '            a += gen.replace(\"▁\", \" \")\\n',\n","    '        print(\"Chatbot > {}\".format(a.strip()))'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/',\n","     'height': 425},\n","    'id': '85g8g8ZixeU8',\n","    'outputId': '16e51a16-e647-4b44-e217-2c0aa5c54215'},\n","   'execution_count': 40,\n","   'outputs': [{'name': 'stdout',\n","     'output_type': 'stream',\n","     'text': ['user > 안녕하세요\\n']},\n","    {'output_type': 'error',\n","     'ename': 'RuntimeError',\n","     'evalue': 'ignored',\n","     'traceback': ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m',\n","      '\\x1b[0;31mRuntimeError\\x1b[0m                              Traceback (most recent call last)',\n","      '\\x1b[0;32m<ipython-input-40-75429edffc48>\\x1b[0m in \\x1b[0;36m<module>\\x1b[0;34m\\x1b[0m\\n\\x1b[1;32m      7\\x1b[0m         \\x1b[0;32mwhile\\x1b[0m \\x1b[0;36m1\\x1b[0m\\x1b[0;34m:\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m      8\\x1b[0m             \\x1b[0minput_ids\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mtorch\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mLongTensor\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mkoGPT2_TOKENIZER\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mencode\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mQ_TKN\\x1b[0m \\x1b[0;34m+\\x1b[0m \\x1b[0mq\\x1b[0m  \\x1b[0;34m+\\x1b[0m \\x1b[0mA_TKN\\x1b[0m \\x1b[0;34m+\\x1b[0m \\x1b[0ma\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0munsqueeze\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mdim\\x1b[0m\\x1b[0;34m=\\x1b[0m\\x1b[0;36m0\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m----> 9\\x1b[0;31m             \\x1b[0mpred\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mmodel\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0minput_ids\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m     10\\x1b[0m             \\x1b[0mpred\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mpred\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mlogits\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m     11\\x1b[0m             \\x1b[0mgen\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mkoGPT2_TOKENIZER\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mconvert_ids_to_tokens\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mtorch\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0margmax\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mpred\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mdim\\x1b[0m\\x1b[0;34m=\\x1b[0m\\x1b[0;34m-\\x1b[0m\\x1b[0;36m1\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0msqueeze\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mnumpy\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mtolist\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m[\\x1b[0m\\x1b[0;34m-\\x1b[0m\\x1b[0;36m1\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\x1b[0m in \\x1b[0;36m_call_impl\\x1b[0;34m(self, *input, **kwargs)\\x1b[0m\\n\\x1b[1;32m   1128\\x1b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\x1b[1;32m   1129\\x1b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\x1b[0;32m-> 1130\\x1b[0;31m             \\x1b[0;32mreturn\\x1b[0m \\x1b[0mforward_call\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m*\\x1b[0m\\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m**\\x1b[0m\\x1b[0mkwargs\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   1131\\x1b[0m         \\x1b[0;31m# Do not call functions when jit is used\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1132\\x1b[0m         \\x1b[0mfull_backward_hooks\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnon_full_backward_hooks\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\x1b[0m in \\x1b[0;36mforward\\x1b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\\x1b[0m\\n\\x1b[1;32m   1044\\x1b[0m         \\x1b[0mreturn_dict\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mreturn_dict\\x1b[0m \\x1b[0;32mif\\x1b[0m \\x1b[0mreturn_dict\\x1b[0m \\x1b[0;32mis\\x1b[0m \\x1b[0;32mnot\\x1b[0m \\x1b[0;32mNone\\x1b[0m \\x1b[0;32melse\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mconfig\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0muse_return_dict\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1045\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m-> 1046\\x1b[0;31m         transformer_outputs = self.transformer(\\n\\x1b[0m\\x1b[1;32m   1047\\x1b[0m             \\x1b[0minput_ids\\x1b[0m\\x1b[0;34m,\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1048\\x1b[0m             \\x1b[0mpast_key_values\\x1b[0m\\x1b[0;34m=\\x1b[0m\\x1b[0mpast_key_values\\x1b[0m\\x1b[0;34m,\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\x1b[0m in \\x1b[0;36m_call_impl\\x1b[0;34m(self, *input, **kwargs)\\x1b[0m\\n\\x1b[1;32m   1128\\x1b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\x1b[1;32m   1129\\x1b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\x1b[0;32m-> 1130\\x1b[0;31m             \\x1b[0;32mreturn\\x1b[0m \\x1b[0mforward_call\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m*\\x1b[0m\\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m**\\x1b[0m\\x1b[0mkwargs\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   1131\\x1b[0m         \\x1b[0;31m# Do not call functions when jit is used\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1132\\x1b[0m         \\x1b[0mfull_backward_hooks\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnon_full_backward_hooks\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\x1b[0m in \\x1b[0;36mforward\\x1b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\\x1b[0m\\n\\x1b[1;32m    830\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    831\\x1b[0m         \\x1b[0;32mif\\x1b[0m \\x1b[0minputs_embeds\\x1b[0m \\x1b[0;32mis\\x1b[0m \\x1b[0;32mNone\\x1b[0m\\x1b[0;34m:\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m--> 832\\x1b[0;31m             \\x1b[0minputs_embeds\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mwte\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0minput_ids\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m    833\\x1b[0m         \\x1b[0mposition_embeds\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mwpe\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mposition_ids\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    834\\x1b[0m         \\x1b[0mhidden_states\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0minputs_embeds\\x1b[0m \\x1b[0;34m+\\x1b[0m \\x1b[0mposition_embeds\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\x1b[0m in \\x1b[0;36m_call_impl\\x1b[0;34m(self, *input, **kwargs)\\x1b[0m\\n\\x1b[1;32m   1128\\x1b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\x1b[1;32m   1129\\x1b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\x1b[0;32m-> 1130\\x1b[0;31m             \\x1b[0;32mreturn\\x1b[0m \\x1b[0mforward_call\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m*\\x1b[0m\\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m**\\x1b[0m\\x1b[0mkwargs\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   1131\\x1b[0m         \\x1b[0;31m# Do not call functions when jit is used\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1132\\x1b[0m         \\x1b[0mfull_backward_hooks\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnon_full_backward_hooks\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\\x1b[0m in \\x1b[0;36mforward\\x1b[0;34m(self, input)\\x1b[0m\\n\\x1b[1;32m    156\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    157\\x1b[0m     \\x1b[0;32mdef\\x1b[0m \\x1b[0mforward\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mself\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0minput\\x1b[0m\\x1b[0;34m:\\x1b[0m \\x1b[0mTensor\\x1b[0m\\x1b[0;34m)\\x1b[0m \\x1b[0;34m->\\x1b[0m \\x1b[0mTensor\\x1b[0m\\x1b[0;34m:\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m--> 158\\x1b[0;31m         return F.embedding(\\n\\x1b[0m\\x1b[1;32m    159\\x1b[0m             \\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mweight\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mpadding_idx\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mmax_norm\\x1b[0m\\x1b[0;34m,\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    160\\x1b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\\x1b[0m in \\x1b[0;36membedding\\x1b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\\x1b[0m\\n\\x1b[1;32m   2197\\x1b[0m         \\x1b[0;31m# remove once script supports set_grad_enabled\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   2198\\x1b[0m         \\x1b[0m_no_grad_embedding_renorm_\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mweight\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mmax_norm\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnorm_type\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m-> 2199\\x1b[0;31m     \\x1b[0;32mreturn\\x1b[0m \\x1b[0mtorch\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0membedding\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mweight\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mpadding_idx\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mscale_grad_by_freq\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0msparse\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   2200\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   2201\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;31mRuntimeError\\x1b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)']}]},\n","  {'cell_type': 'code',\n","   'source': [],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': 'QO5VC8WLyThv',\n","    'outputId': '169e4e53-4475-4c42-b58b-1b7b8263e59e'},\n","   'execution_count': 38,\n","   'outputs': [{'output_type': 'execute_result',\n","     'data': {'text/plain': ['True']},\n","     'metadata': {},\n","     'execution_count': 38}]}]}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["!pip install transformers -q"],"metadata":{"id":"nKj9W1DApS5r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670390145117,"user_tz":-540,"elapsed":9535,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"4c037362-3614-4c1a-9ee5-a958073ad523"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 5.8 MB 5.0 MB/s \n","\u001b[K     |████████████████████████████████| 7.6 MB 69.4 MB/s \n","\u001b[K     |████████████████████████████████| 182 kB 81.2 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast"],"metadata":{"id":"pRofYonM4OG2","executionInfo":{"status":"ok","timestamp":1670390164258,"user_tz":-540,"elapsed":4247,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPbgLfsx4o6k","executionInfo":{"status":"ok","timestamp":1670390152852,"user_tz":-540,"elapsed":7744,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"18978f98-9799-4bc7-d8a0-c27b06eb13ff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.8.3.post1-py3-none-any.whl (798 kB)\n","\u001b[K     |████████████████████████████████| 798 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |████████████████████████████████| 512 kB 92.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.1.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n","Collecting lightning-utilities==0.3.*\n","  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n","Collecting tensorboardX>=2.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |████████████████████████████████| 125 kB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n","Collecting fire\n","  Downloading fire-0.4.0.tar.gz (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=8df824abcb6437e0923e9487751ce6b8579cbd55daf5230b6789c6f6223d9743\n","  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n","Successfully built fire\n","Installing collected packages: fire, torchmetrics, tensorboardX, lightning-utilities, pytorch-lightning\n","Successfully installed fire-0.4.0 lightning-utilities-0.3.0 pytorch-lightning-1.8.3.post1 tensorboardX-2.5.1 torchmetrics-0.11.0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re"],"metadata":{"id":"7HCJPABx4-HO","executionInfo":{"status":"ok","timestamp":1670390175814,"user_tz":-540,"elapsed":555,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = '</s>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","SENT = '<unused1>'\n","PAD = '<pad>'"],"metadata":{"id":"Wy3wj1ak4uNY","executionInfo":{"status":"ok","timestamp":1670390180273,"user_tz":-540,"elapsed":2,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK) \n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["529d0bd240124ad0996beb37b84df0c4","a4409363d601444080dc231d66ac04f9","2f1d96ea89f64c02859f552513f82569","2009ae2d8659480ba38e2b52bd50b785","99fd91bd21dc424cb125b8bf82103060","2870d1f79d0a4c269b2013c5ae04207e","e18cd0870770401998906f5ae942656c","07485e67417a49d1b5991cc7dd93f9ad","796a8f17426d47b2a98f4c4b114449d9","2c974a4d736e4e0aa8fb2e1df8dfaeab","295f636c11ec4986ba5e6881d72dfd18","36ff5032b1794d7da83f50b83b6a1028","be485e1609a8482b88f3df0e2f2a5b95","ad1f4688080140b2a20cbf1f6181799e","31502d43ca5a45d0b70dc48e0ced499b","5365579db72b479f90d9685ecdc74147","7411adacb2f3470ab8263e0c06cefa82","0df0ccdf19e94451b4145bd87c5f69e8","44e1d7882c7b42309ef68716b3e6196a","03afb31c12ce4f16ae09aed113841922","f35e313cc3734264bfb68116284cda4d","7a3085ace50b4999b8484a02ee6d574b","06731cf712ea4e1ca8102ef493ad3d7b","ecdddbfa4053423c8144e3a9f6b87bf3","f55b22ff46da49e2b9fd805bb3cd6cd3","70caf097c22e4729a849c7bfea8d7c35","349af36cef2c40329b54da9b5abf20be","78309c57a9d448a5926233889db761e7","869107e0430f4568b223c5e319b85f3e","595929dc195449c5b76c630716d07135","e424ba393b9f44119c3d429ab82ce936","e6a3ee1c1dbe42fdaae7a0d69d348f3d","088c7fe8517643c09348444dd8ac1a51"]},"id":"VVD1JqTJ40I9","executionInfo":{"status":"ok","timestamp":1670390207984,"user_tz":-540,"elapsed":25788,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"6a656759-517c-44ff-82b3-e6bd8ac9a58d"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"529d0bd240124ad0996beb37b84df0c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ff5032b1794d7da83f50b83b6a1028"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06731cf712ea4e1ca8102ef493ad3d7b"}},"metadata":{}}]},{"cell_type":"code","source":["# 챗봇 데이터를 처리하는 클래스를 만든다.\n","class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # 질문을 가져온다.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # 구둣점들을 제거한다.\n","\n","        a = turn[\"A\"]  # 답변을 가져온다.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # 구둣점들을 제거한다.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        #질문의 길이가 최대길이보다 크면\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n","            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        #질문의 길이 + 답변의 길이가 최대길이보다 크면\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len        #답변의 길이를 최대길이 - 질문길이\n","            if a_len <= 0:       #질문의 길이가 너무 길어 질문만으로 최대 길이를 초과 한다면\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #질문길이를 최대길이의 반으로 \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #답변의 길이를 최대길이 - 질문길이\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # 답변 labels = [mask, mask, ...., mask, ..., <bos>,..답변.. <eos>, <pad>....]\n","        labels = [self.mask,] * q_len + a_toked[1:]\n","\n","        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # 답변 labels을 index 로 만든다.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # 최대길이만큼 PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # 질문 + 답변을 index 로 만든다.    \n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # 최대길이만큼 PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        #질문+답변, 마스크, 답변\n","        return (token_ids, np.array(mask), labels_ids)"],"metadata":{"id":"vkAHvUKP4QAn","executionInfo":{"status":"ok","timestamp":1670390207985,"user_tz":-540,"elapsed":10,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"],"metadata":{"id":"4YmgAlnB4Rgn","executionInfo":{"status":"ok","timestamp":1670390207986,"user_tz":-540,"elapsed":8,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#데이터셋 불러오는 부분\n","import urllib.request\n","\n","urllib.request.urlretrieve(\n","    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n","    filename=\"ChatBotData.csv\",\n",")\n","Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n","\n","# Test 용으로 300개 데이터만 처리한다.\n","# Chatbot_Data = Chatbot_Data[:300]\n","# Chatbot_Data.head(20)"],"metadata":{"id":"pOuW4Tiw4TD4","executionInfo":{"status":"ok","timestamp":1670378186891,"user_tz":-540,"elapsed":1589,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data = pd.read_csv(\"totaldf.csv\")"],"metadata":{"id":"bbnz6g_kAlYT","executionInfo":{"status":"ok","timestamp":1670390207986,"user_tz":-540,"elapsed":7,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.drop('label',axis=1,inplace=True)"],"metadata":{"id":"22CmS2M8TG9A","executionInfo":{"status":"ok","timestamp":1670378217497,"user_tz":-540,"elapsed":9,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data[Chatbot_Data['Q'].str.contains('점심')]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"Dzn0ZTmwwd4m","executionInfo":{"status":"ok","timestamp":1670289165727,"user_tz":-540,"elapsed":321,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"da7e2248-e9db-42de-b7ba-9d9ec3da2896"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                   Q                       A  label\n","3310                     오늘 점심 뭐 먹을까               냉면은 어떠세요?      0\n","3311                          오늘 점심은     날씨도 추운데 뜨끈한 국물 드세요!      0\n","4116                 점심 도시락 싸는 거 귀찮다     건강을 챙긴다는 마음으로 해보세요.      0\n","4117                   점심 때 은행 갔다와야지              볼 일이 있나봐요.      0\n","4118                         점심 먹어야지       즐거운 시간 보내시길 바랍니다.      0\n","4119                 점심 메뉴 고르는 거 힘드네          맞아요 항상 고민이 되죠.      0\n","4120                     점심 메뉴 좀 골라줘  주변 분들의 얘기를 들어보는건 어떨까요?      0\n","4121                      점심시간 너무 짧아             일하는 시간은 길죠.      0\n","4122             점심시간에 외출하는 것도 눈치봐야돼     정말 너무하네요 개인적인 시간인데.      0\n","4123                 점심시간에 외출하면 안 되나         시간안에만 온다면 가능하죠.      0\n","4124                  점심시간에 은행 갔다와야지              볼 일이 있나봐요.      0\n","4125                  점심시간엔 그냥 쉬고 싶어  맛난거 드시고 조금이라도 쉬셔야 할텐데.      0\n","4126             점심시간이라도 마음 놓고 쉬고 싶어  맛난거 드시고 조금이라도 쉬셔야 할텐데.      0\n","7700     이제 점심시간에도 너에게 카톡을 할 수가 없구나.  점심시간에 할 수 있는 다른 걸 해봐요.      1\n","8008   점심시간잠깐 그녀가 저에게 했던 말들이 떠오르네~ㅠㅠ       생각을 접어두는 것도 필요해요.      1\n","11002              점심시간일 텐데 카톡이 안 와.      먼저 연락을 해보는 건 어떨까요?      2"],"text/html":["\n","  <div id=\"df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3310</th>\n","      <td>오늘 점심 뭐 먹을까</td>\n","      <td>냉면은 어떠세요?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3311</th>\n","      <td>오늘 점심은</td>\n","      <td>날씨도 추운데 뜨끈한 국물 드세요!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4116</th>\n","      <td>점심 도시락 싸는 거 귀찮다</td>\n","      <td>건강을 챙긴다는 마음으로 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4117</th>\n","      <td>점심 때 은행 갔다와야지</td>\n","      <td>볼 일이 있나봐요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4118</th>\n","      <td>점심 먹어야지</td>\n","      <td>즐거운 시간 보내시길 바랍니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4119</th>\n","      <td>점심 메뉴 고르는 거 힘드네</td>\n","      <td>맞아요 항상 고민이 되죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4120</th>\n","      <td>점심 메뉴 좀 골라줘</td>\n","      <td>주변 분들의 얘기를 들어보는건 어떨까요?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4121</th>\n","      <td>점심시간 너무 짧아</td>\n","      <td>일하는 시간은 길죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4122</th>\n","      <td>점심시간에 외출하는 것도 눈치봐야돼</td>\n","      <td>정말 너무하네요 개인적인 시간인데.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4123</th>\n","      <td>점심시간에 외출하면 안 되나</td>\n","      <td>시간안에만 온다면 가능하죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4124</th>\n","      <td>점심시간에 은행 갔다와야지</td>\n","      <td>볼 일이 있나봐요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4125</th>\n","      <td>점심시간엔 그냥 쉬고 싶어</td>\n","      <td>맛난거 드시고 조금이라도 쉬셔야 할텐데.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4126</th>\n","      <td>점심시간이라도 마음 놓고 쉬고 싶어</td>\n","      <td>맛난거 드시고 조금이라도 쉬셔야 할텐데.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7700</th>\n","      <td>이제 점심시간에도 너에게 카톡을 할 수가 없구나.</td>\n","      <td>점심시간에 할 수 있는 다른 걸 해봐요.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8008</th>\n","      <td>점심시간잠깐 그녀가 저에게 했던 말들이 떠오르네~ㅠㅠ</td>\n","      <td>생각을 접어두는 것도 필요해요.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11002</th>\n","      <td>점심시간일 텐데 카톡이 안 와.</td>\n","      <td>먼저 연락을 해보는 건 어떨까요?</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4122]='정말 너무하네요 개인적인 시간인데.'"],"metadata":{"id":"uzYA10CR-uNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4123]='시간안에만 온다면 가능하죠.'"],"metadata":{"id":"heLvDrEh-9qK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4119]='맞아요 항상 고민이 되죠.'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3P_9PPaB-E-R","executionInfo":{"status":"ok","timestamp":1670289161420,"user_tz":-540,"elapsed":272,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"2d624e7d-e48b-4f3c-db8c-8a092532e964"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4119]='맞아요 항상 고민이되죠.'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSGhspDm-mGP","executionInfo":{"status":"ok","timestamp":1670288947077,"user_tz":-540,"elapsed":260,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"dac00148-93a3-4e7b-f0c1-f6bce9140d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4120]='주변 분들의 얘기를 들어보는건 어떨까요?'"],"metadata":{"id":"4GUWmaej-dtv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[3311]='날씨도 추운데 뜨끈한 국물 드세요!'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-TZE8eN-MdY","executionInfo":{"status":"ok","timestamp":1670288845870,"user_tz":-540,"elapsed":251,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"2dcee5fb-bb22-4f13-84a4-db7263c4559b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[808]='그럴리가요 확인해보세요.'"],"metadata":{"id":"4kE1Pa5k3PEU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670288758962,"user_tz":-540,"elapsed":251,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"dd8f74ce-fdb1-459b-ea2a-d19cbd443a3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data=Chatbot_Data.copy()"],"metadata":{"id":"7C1kRZjG0PlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.to_csv('chatbotdata.csv',encoding='cp949')"],"metadata":{"id":"f0o6c-570xLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[3691]='쫑긋이에요.'"],"metadata":{"id":"ho4jMcd0zeU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')"],"metadata":{"id":"o1ZqGb2_BPrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","#윈도우 환경에서 num_workers 는 무조건 0으로 지정, 리눅스에서는 2\n","train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)"],"metadata":{"id":"LADrzGWw4S_R","executionInfo":{"status":"ok","timestamp":1670390539701,"user_tz":-540,"elapsed":277,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mElEmpnS4S83","executionInfo":{"status":"ok","timestamp":1670390542123,"user_tz":-540,"elapsed":7,"user":{"displayName":"박시호","userId":"04591515150809458724"}},"outputId":"cd12f575-880f-4ef0-9092-cd5c0cfeeae4"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["Chatbot_Data.drop(['Unnamed: 0','구분'],axis=1,inplace=True)"],"metadata":{"id":"D3VohQPtBFST","executionInfo":{"status":"ok","timestamp":1670390329809,"user_tz":-540,"elapsed":257,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.rename(columns = {'유저' : 'Q','챗봇':'A'}, inplace = True)"],"metadata":{"id":"eM0n29TQBbsb","executionInfo":{"status":"ok","timestamp":1670390416961,"user_tz":-540,"elapsed":305,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.to_csv('datset.csv',encoding='cp949')"],"metadata":{"id":"hmAVJjDWBw7J","executionInfo":{"status":"ok","timestamp":1670390448106,"user_tz":-540,"elapsed":252,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epoch = 10\n","Sneg = -1e18"],"metadata":{"id":"Nh9gnnTG5GKF","executionInfo":{"status":"ok","timestamp":1670390549322,"user_tz":-540,"elapsed":259,"user":{"displayName":"박시호","userId":"04591515150809458724"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"VxFluYy186Uj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (\"start\")\n","for epoch in range(epoch):\n","    for batch_idx, samples in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        out = model(token_ids)\n","        out = out.logits      #Returns a new tensor with the logit of the elements of input\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        # 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\n","        avg_loss = loss.sum() / mask.sum()\n","        avg_loss.backward()\n","        # 학습 끝\n","        optimizer.step()\n","print (\"end\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ed7rniu5GH5","outputId":"e3685b23-ffd4-454a-fdc3-277f522f4cc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["start\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q  + A_TKN + a)).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"▁\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"],"metadata":{"id":"2Xo-3vp27lwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH = ''"],"metadata":{"id":"NB2si4tGsDgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model,PATH+'save_model')"],"metadata":{"id":"JhXQx6fA7loY"},"execution_count":null,"outputs":[]}]}