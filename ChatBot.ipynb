{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1JmUNOIjol8u6LibX5yEZR_XkJzRvGJKO","timestamp":1670423407656},{"file_id":"18u4tuZPeiHn7shIUYRj6ZdKuOyBUbe5L","timestamp":1670153378168},{"file_id":"1DKFUPzxhGWGB_ZoYgN_ikv4P4nYf25K4","timestamp":1669941198963}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"529d0bd240124ad0996beb37b84df0c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4409363d601444080dc231d66ac04f9","IPY_MODEL_2f1d96ea89f64c02859f552513f82569","IPY_MODEL_2009ae2d8659480ba38e2b52bd50b785"],"layout":"IPY_MODEL_99fd91bd21dc424cb125b8bf82103060"}},"a4409363d601444080dc231d66ac04f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2870d1f79d0a4c269b2013c5ae04207e","placeholder":"‚Äã","style":"IPY_MODEL_e18cd0870770401998906f5ae942656c","value":"Downloading: 100%"}},"2f1d96ea89f64c02859f552513f82569":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07485e67417a49d1b5991cc7dd93f9ad","max":2825034,"min":0,"orientation":"horizontal","style":"IPY_MODEL_796a8f17426d47b2a98f4c4b114449d9","value":2825034}},"2009ae2d8659480ba38e2b52bd50b785":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2c974a4d736e4e0aa8fb2e1df8dfaeab","placeholder":"‚Äã","style":"IPY_MODEL_295f636c11ec4986ba5e6881d72dfd18","value":" 2.83M/2.83M [00:00&lt;00:00, 5.54MB/s]"}},"99fd91bd21dc424cb125b8bf82103060":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2870d1f79d0a4c269b2013c5ae04207e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e18cd0870770401998906f5ae942656c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07485e67417a49d1b5991cc7dd93f9ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796a8f17426d47b2a98f4c4b114449d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2c974a4d736e4e0aa8fb2e1df8dfaeab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"295f636c11ec4986ba5e6881d72dfd18":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"36ff5032b1794d7da83f50b83b6a1028":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_be485e1609a8482b88f3df0e2f2a5b95","IPY_MODEL_ad1f4688080140b2a20cbf1f6181799e","IPY_MODEL_31502d43ca5a45d0b70dc48e0ced499b"],"layout":"IPY_MODEL_5365579db72b479f90d9685ecdc74147"}},"be485e1609a8482b88f3df0e2f2a5b95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7411adacb2f3470ab8263e0c06cefa82","placeholder":"‚Äã","style":"IPY_MODEL_0df0ccdf19e94451b4145bd87c5f69e8","value":"Downloading: 100%"}},"ad1f4688080140b2a20cbf1f6181799e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_44e1d7882c7b42309ef68716b3e6196a","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_03afb31c12ce4f16ae09aed113841922","value":1000}},"31502d43ca5a45d0b70dc48e0ced499b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f35e313cc3734264bfb68116284cda4d","placeholder":"‚Äã","style":"IPY_MODEL_7a3085ace50b4999b8484a02ee6d574b","value":" 1.00k/1.00k [00:00&lt;00:00, 40.8kB/s]"}},"5365579db72b479f90d9685ecdc74147":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7411adacb2f3470ab8263e0c06cefa82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0df0ccdf19e94451b4145bd87c5f69e8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"44e1d7882c7b42309ef68716b3e6196a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03afb31c12ce4f16ae09aed113841922":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f35e313cc3734264bfb68116284cda4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a3085ace50b4999b8484a02ee6d574b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06731cf712ea4e1ca8102ef493ad3d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ecdddbfa4053423c8144e3a9f6b87bf3","IPY_MODEL_f55b22ff46da49e2b9fd805bb3cd6cd3","IPY_MODEL_70caf097c22e4729a849c7bfea8d7c35"],"layout":"IPY_MODEL_349af36cef2c40329b54da9b5abf20be"}},"ecdddbfa4053423c8144e3a9f6b87bf3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78309c57a9d448a5926233889db761e7","placeholder":"‚Äã","style":"IPY_MODEL_869107e0430f4568b223c5e319b85f3e","value":"Downloading: 100%"}},"f55b22ff46da49e2b9fd805bb3cd6cd3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_595929dc195449c5b76c630716d07135","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e424ba393b9f44119c3d429ab82ce936","value":513302779}},"70caf097c22e4729a849c7bfea8d7c35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6a3ee1c1dbe42fdaae7a0d69d348f3d","placeholder":"‚Äã","style":"IPY_MODEL_088c7fe8517643c09348444dd8ac1a51","value":" 513M/513M [00:21&lt;00:00, 23.2MB/s]"}},"349af36cef2c40329b54da9b5abf20be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78309c57a9d448a5926233889db761e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"869107e0430f4568b223c5e319b85f3e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"595929dc195449c5b76c630716d07135":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e424ba393b9f44119c3d429ab82ce936":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e6a3ee1c1dbe42fdaae7a0d69d348f3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"088c7fe8517643c09348444dd8ac1a51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["# ag_train['num_len']=ag_train.Utterance.apply(lambda x:len(x))"],"metadata":{"id":"x_thQQeBJg3r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop(ag_train[ag_train.num_len==1].index,inplace=True)"],"metadata":{"id":"JGxiLPuAGTdE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# trying=ag_train[(ag_train.num_len==3)&(ag_train.Target=='neutral')]['Utterance'].index"],"metadata":{"id":"vRrvT15DIaCh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"tgkaCEnMvKYC"}},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying1]=ag_train['Utterance'][(ag_train.num_len==4)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"q6coOTtla-oo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying2]=ag_train['Utterance'][(ag_train.num_len==5)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"nlDfluaZjeIg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying3]=ag_train['Utterance'][(ag_train.num_len==6)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"BmOGcBpeu6cD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying4]=ag_train['Utterance'][(ag_train.num_len==7)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"id":"m3NwwGue0Z9o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.Utterance.loc[trying5]=ag_train['Utterance'][(ag_train.num_len<20)&(ag_train.Target=='neutral')].str.replace(pat=r'[^\\w]', repl=r' ', regex=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOf758704rk-","executionInfo":{"status":"ok","timestamp":1670204786035,"user_tz":-540,"elapsed":554,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"e6017eb8-979d-47e9-e2c7-2cedb8a19981"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["# ag_train.drop(ag_train[(ag_train.num_len==2)&(ag_train.Target!='neutral')].index,inplace=True)"],"metadata":{"id":"gl5kYKs-HtUJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop(ag_train[(ag_train.num_len==3)&(ag_train.Target=='neutral')].index,inplace=True)"],"metadata":{"id":"L4d1dtrj3iB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop(ag_train[(ag_train.num_len>5)&(ag_train.Target=='neutral')].index,inplace=True)"],"metadata":{"id":"1pW4IKAa7svD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ag_train.drop('num_len',axis=1,inplace=True)"],"metadata":{"id":"auXNdM9fIdvu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZcR5__j2mknU","executionInfo":{"status":"ok","timestamp":1670287344928,"user_tz":-540,"elapsed":3963,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"ccb240f1-24f2-4dca-ab23-b86a92072afb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.25.1)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.11.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n"]}]},{"cell_type":"code","source":["{\n","  \"nbformat\": 4,\n","  \"nbformat_minor\": 0,\n","  \"metadata\": {\n","    \"colab\": {\n","      \"provenance\": [],\n","      \"machine_shape\": \"hm\"\n","    },\n","    \"kernelspec\": {\n","      \"name\": \"python3\",\n","      \"display_name\": \"Python 3\"\n","    },\n","    \"language_info\": {\n","      \"name\": \"python\"\n","    },\n","    \"accelerator\": \"GPU\",\n","    \"gpuClass\": \"standard\"\n","  },\n","  \"cells\": [\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"!pip install transformers -q\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"Ax2iPY0JuKAC\"\n","      },\n","      \"execution_count\": 6,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"# Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï≤òÎ¶¨ÌïòÎäî ÌÅ¥ÎûòÏä§Î•º ÎßåÎì†Îã§.\\n\",\n","        \"class ChatbotDataset(Dataset):\\n\",\n","        \"    def __init__(self, chats, max_len=40):  # Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Ï†ÑÏ≤òÎ¶¨Î•º Ìï¥Ï£ºÎäî Î∂ÄÎ∂Ñ\\n\",\n","        \"        self._data = chats\\n\",\n","        \"        self.max_len = max_len\\n\",\n","        \"        self.q_token = Q_TKN\\n\",\n","        \"        self.a_token = A_TKN\\n\",\n","        \"        self.sent_token = SENT\\n\",\n","        \"        self.eos = EOS\\n\",\n","        \"        self.mask = MASK\\n\",\n","        \"        self.tokenizer = koGPT2_TOKENIZER\\n\",\n","        \"\\n\",\n","        \"    def __len__(self):  # chatbotdata Ïùò Í∏∏Ïù¥Î•º Î¶¨ÌÑ¥ÌïúÎã§.\\n\",\n","        \"        return len(self._data)\\n\",\n","        \"\\n\",\n","        \"    def __getitem__(self, idx):  # Î°úÎìúÌïú Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï∞®Î°ÄÏ∞®Î°Ä DataLoaderÎ°ú ÎÑòÍ≤®Ï£ºÎäî Î©îÏÑúÎìú\\n\",\n","        \"        turn = self._data.iloc[idx]\\n\",\n","        \"        q = turn[\\\"Q\\\"]  # ÏßàÎ¨∏ÏùÑ Í∞ÄÏ†∏Ïò®Îã§.\\n\",\n","        \"        q = re.sub(r\\\"([?.!,])\\\", r\\\" \\\", q)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.\\n\",\n","        \"\\n\",\n","        \"        a = turn[\\\"A\\\"]  # ÎãµÎ≥ÄÏùÑ Í∞ÄÏ†∏Ïò®Îã§.\\n\",\n","        \"        a = re.sub(r\\\"([?.!,])\\\", r\\\" \\\", a)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.\\n\",\n","        \"\\n\",\n","        \"        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\\n\",\n","        \"        q_len = len(q_toked)\\n\",\n","        \"\\n\",\n","        \"        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\\n\",\n","        \"        a_len = len(a_toked)\\n\",\n","        \"\\n\",\n","        \"        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥\\n\",\n","        \"        if q_len > self.max_len:\\n\",\n","        \"            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n\",\n","        \"            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥\\n\",\n","        \"                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú \\n\",\n","        \"                q_len = len(q_toked)\\n\",\n","        \"                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n\",\n","        \"            a_toked = a_toked[:a_len]\\n\",\n","        \"            a_len = len(a_toked)\\n\",\n","        \"\\n\",\n","        \"        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥ + ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥\\n\",\n","        \"        if q_len + a_len > self.max_len:\\n\",\n","        \"            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n\",\n","        \"            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥\\n\",\n","        \"                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú \\n\",\n","        \"                q_len = len(q_toked)\\n\",\n","        \"                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n\",\n","        \"            a_toked = a_toked[:a_len]\\n\",\n","        \"            a_len = len(a_toked)\\n\",\n","        \"\\n\",\n","        \"        # ÎãµÎ≥Ä labels = [mask, mask, ...., mask, ..., <bos>,..ÎãµÎ≥Ä.. <eos>, <pad>....]\\n\",\n","        \"        labels = [self.mask,] * q_len + a_toked[1:]\\n\",\n","        \"\\n\",\n","        \"        # mask = ÏßàÎ¨∏Í∏∏Ïù¥ 0 + ÎãµÎ≥ÄÍ∏∏Ïù¥ 1 + ÎÇòÎ®∏ÏßÄ 0\\n\",\n","        \"        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\\n\",\n","        \"        # ÎãµÎ≥Ä labelsÏùÑ index Î°ú ÎßåÎì†Îã§.\\n\",\n","        \"        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\\n\",\n","        \"        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING\\n\",\n","        \"        while len(labels_ids) < self.max_len:\\n\",\n","        \"            labels_ids += [self.tokenizer.pad_token_id]\\n\",\n","        \"\\n\",\n","        \"        # ÏßàÎ¨∏ + ÎãµÎ≥ÄÏùÑ index Î°ú ÎßåÎì†Îã§.    \\n\",\n","        \"        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\\n\",\n","        \"        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING\\n\",\n","        \"        while len(token_ids) < self.max_len:\\n\",\n","        \"            token_ids += [self.tokenizer.pad_token_id]\\n\",\n","        \"\\n\",\n","        \"        #ÏßàÎ¨∏+ÎãµÎ≥Ä, ÎßàÏä§ÌÅ¨, ÎãµÎ≥Ä\\n\",\n","        \"        return (token_ids, np.array(mask), labels_ids)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"wtSydcC3uJq0\"\n","      },\n","      \"execution_count\": 7,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"def collate_batch(batch):\\n\",\n","        \"    data = [item[0] for item in batch]\\n\",\n","        \"    mask = [item[1] for item in batch]\\n\",\n","        \"    label = [item[2] for item in batch]\\n\",\n","        \"    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"7Eo3Lg5AuJuC\"\n","      },\n","      \"execution_count\": 9,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n\",\n","        \"\\n\",\n","        \"#ÏúàÎèÑÏö∞ ÌôòÍ≤ΩÏóêÏÑú num_workers Îäî Î¨¥Ï°∞Í±¥ 0ÏúºÎ°ú ÏßÄÏ†ï, Î¶¨ÎàÖÏä§ÏóêÏÑúÎäî 2\\n\",\n","        \"train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"HflM0VSJudYO\"\n","      },\n","      \"execution_count\": 23,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"import torch\\n\",\n","        \"from transformers import GPT2LMHeadModel\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"CxDjdgREvEjO\"\n","      },\n","      \"execution_count\": 15,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"from transformers import PreTrainedTokenizerFast\\n\",\n","        \"tokenizer = PreTrainedTokenizerFast.from_pretrained(\\\"skt/kogpt2-base-v2\\\", bos_token='</s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<mask>') \\n\",\n","        \"tokenizer.tokenize(\\\"ÏïàÎÖïÌïòÏÑ∏Ïöî. ÌïúÍµ≠Ïñ¥ GPT-2 ÏûÖÎãàÎã§.üò§:)l^o\\\")\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"HGMBg0oWvEmG\",\n","        \"outputId\": \"b83b9538-220c-41b9-a85a-091cd09606cd\"\n","      },\n","      \"execution_count\": 16,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stderr\",\n","          \"text\": [\n","            \"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n\",\n","            \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","            \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"\n","          ]\n","        },\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"['‚ñÅÏïàÎÖï',\\n\",\n","              \" 'Ìïò',\\n\",\n","              \" 'ÏÑ∏',\\n\",\n","              \" 'Ïöî.',\\n\",\n","              \" '‚ñÅÌïúÍµ≠Ïñ¥',\\n\",\n","              \" '‚ñÅG',\\n\",\n","              \" 'P',\\n\",\n","              \" 'T',\\n\",\n","              \" '-2',\\n\",\n","              \" '‚ñÅÏûÖ',\\n\",\n","              \" 'ÎãàÎã§.',\\n\",\n","              \" 'üò§',\\n\",\n","              \" ':)',\\n\",\n","              \" 'l^o']\"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 16\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"!pip install pytorch_lightning -q\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"GcszoiwMvX4Y\",\n","        \"outputId\": \"bf18fa61-232b-4fb0-c6d7-6325f673171d\"\n","      },\n","      \"execution_count\": 1,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stdout\",\n","          \"text\": [\n","            \"Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n\",\n","            \"Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.8.3.post1)\\n\",\n","            \"Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\\n\",\n","            \"Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.1.1)\\n\",\n","            \"Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\\n\",\n","            \"Requirement already satisfied: lightning-utilities==0.3.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.3.0)\\n\",\n","            \"Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\\n\",\n","            \"Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.1+cu113)\\n\",\n","            \"Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.0)\\n\",\n","            \"Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.5.1)\\n\",\n","            \"Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\\n\",\n","            \"Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\\n\",\n","            \"Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (from lightning-utilities==0.3.*->pytorch_lightning) (0.4.0)\\n\",\n","            \"Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\\n\",\n","            \"Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\\n\",\n","            \"Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\\n\",\n","            \"Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\\n\",\n","            \"Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\\n\",\n","            \"Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\\n\",\n","            \"Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\\n\",\n","            \"Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\\n\",\n","            \"Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\\n\",\n","            \"Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\\n\",\n","            \"Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\\n\",\n","            \"Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\\n\",\n","            \"Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\\n\",\n","            \"Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.15.0)\\n\",\n","            \"Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\\n\",\n","            \"Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\\n\",\n","            \"Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\\n\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"import numpy as np\\n\",\n","        \"import pandas as pd\\n\",\n","        \"import torch\\n\",\n","        \"from pytorch_lightning import Trainer\\n\",\n","        \"from pytorch_lightning.callbacks import ModelCheckpoint\\n\",\n","        \"from pytorch_lightning.core.lightning import LightningModule\\n\",\n","        \"from torch.utils.data import DataLoader, Dataset\\n\",\n","        \"from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\\n\",\n","        \"from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\\n\",\n","        \"import re\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"GKeLSiYmvExD\"\n","      },\n","      \"execution_count\": 28,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"Q_TKN = \\\"<usr>\\\"\\n\",\n","        \"A_TKN = \\\"<sys>\\\"\\n\",\n","        \"BOS = '</s>'\\n\",\n","        \"EOS = '</s>'\\n\",\n","        \"MASK = '<unused0>'\\n\",\n","        \"SENT = '<unused1>'\\n\",\n","        \"PAD = '<pad>'\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"6uciWc48vEzr\"\n","      },\n","      \"execution_count\": 29,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\\\"skt/kogpt2-base-v2\\\",\\n\",\n","        \"            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\\n\",\n","        \"            pad_token=PAD, mask_token=MASK) \\n\",\n","        \"model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"9by9OEqrvE2K\",\n","        \"outputId\": \"b49002e4-4f6d-48c1-9052-831070ac0117\"\n","      },\n","      \"execution_count\": 30,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stderr\",\n","          \"text\": [\n","            \"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n\",\n","            \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","            \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"import urllib.request\\n\",\n","        \"\\n\",\n","        \"urllib.request.urlretrieve(\\n\",\n","        \"    \\\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\\\",\\n\",\n","        \"    filename=\\\"ChatBotData.csv\\\",\\n\",\n","        \")\\n\",\n","        \"Chatbot_Data = pd.read_csv(\\\"ChatBotData.csv\\\")\\n\",\n","        \"# Test Ïö©ÏúºÎ°ú 300Í∞ú Îç∞Ïù¥ÌÑ∞Îßå Ï≤òÎ¶¨ÌïúÎã§.\\n\",\n","        \"Chatbot_Data = Chatbot_Data[:300]\\n\",\n","        \"Chatbot_Data.head()\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\",\n","          \"height\": 206\n","        },\n","        \"id\": \"riP0GLx7vE4f\",\n","        \"outputId\": \"c44e7367-4948-4def-bc8d-b6f4c54cb685\"\n","      },\n","      \"execution_count\": 31,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"                 Q            A  label\\n\",\n","              \"0           12Ïãú Îï°!   ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.      0\\n\",\n","              \"1      1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥    ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.      0\\n\",\n","              \"2     3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\\n\",\n","              \"3  3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\\n\",\n","              \"4          PPL Ïã¨ÌïòÎÑ§   ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.      0\"\n","            ],\n","            \"text/html\": [\n","              \"\\n\",\n","              \"  <div id=\\\"df-6907237d-e6c5-4927-95da-536fb96e400b\\\">\\n\",\n","              \"    <div class=\\\"colab-df-container\\\">\\n\",\n","              \"      <div>\\n\",\n","              \"<style scoped>\\n\",\n","              \"    .dataframe tbody tr th:only-of-type {\\n\",\n","              \"        vertical-align: middle;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .dataframe tbody tr th {\\n\",\n","              \"        vertical-align: top;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .dataframe thead th {\\n\",\n","              \"        text-align: right;\\n\",\n","              \"    }\\n\",\n","              \"</style>\\n\",\n","              \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n","              \"  <thead>\\n\",\n","              \"    <tr style=\\\"text-align: right;\\\">\\n\",\n","              \"      <th></th>\\n\",\n","              \"      <th>Q</th>\\n\",\n","              \"      <th>A</th>\\n\",\n","              \"      <th>label</th>\\n\",\n","              \"    </tr>\\n\",\n","              \"  </thead>\\n\",\n","              \"  <tbody>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>0</th>\\n\",\n","              \"      <td>12Ïãú Îï°!</td>\\n\",\n","              \"      <td>ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>1</th>\\n\",\n","              \"      <td>1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥</td>\\n\",\n","              \"      <td>ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>2</th>\\n\",\n","              \"      <td>3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\\n\",\n","              \"      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>3</th>\\n\",\n","              \"      <td>3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\\n\",\n","              \"      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"    <tr>\\n\",\n","              \"      <th>4</th>\\n\",\n","              \"      <td>PPL Ïã¨ÌïòÎÑ§</td>\\n\",\n","              \"      <td>ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.</td>\\n\",\n","              \"      <td>0</td>\\n\",\n","              \"    </tr>\\n\",\n","              \"  </tbody>\\n\",\n","              \"</table>\\n\",\n","              \"</div>\\n\",\n","              \"      <button class=\\\"colab-df-convert\\\" onclick=\\\"convertToInteractive('df-6907237d-e6c5-4927-95da-536fb96e400b')\\\"\\n\",\n","              \"              title=\\\"Convert this dataframe to an interactive table.\\\"\\n\",\n","              \"              style=\\\"display:none;\\\">\\n\",\n","              \"        \\n\",\n","              \"  <svg xmlns=\\\"http://www.w3.org/2000/svg\\\" height=\\\"24px\\\"viewBox=\\\"0 0 24 24\\\"\\n\",\n","              \"       width=\\\"24px\\\">\\n\",\n","              \"    <path d=\\\"M0 0h24v24H0V0z\\\" fill=\\\"none\\\"/>\\n\",\n","              \"    <path d=\\\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\\\"/><path d=\\\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\\\"/>\\n\",\n","              \"  </svg>\\n\",\n","              \"      </button>\\n\",\n","              \"      \\n\",\n","              \"  <style>\\n\",\n","              \"    .colab-df-container {\\n\",\n","              \"      display:flex;\\n\",\n","              \"      flex-wrap:wrap;\\n\",\n","              \"      gap: 12px;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .colab-df-convert {\\n\",\n","              \"      background-color: #E8F0FE;\\n\",\n","              \"      border: none;\\n\",\n","              \"      border-radius: 50%;\\n\",\n","              \"      cursor: pointer;\\n\",\n","              \"      display: none;\\n\",\n","              \"      fill: #1967D2;\\n\",\n","              \"      height: 32px;\\n\",\n","              \"      padding: 0 0 0 0;\\n\",\n","              \"      width: 32px;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    .colab-df-convert:hover {\\n\",\n","              \"      background-color: #E2EBFA;\\n\",\n","              \"      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\\n\",\n","              \"      fill: #174EA6;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    [theme=dark] .colab-df-convert {\\n\",\n","              \"      background-color: #3B4455;\\n\",\n","              \"      fill: #D2E3FC;\\n\",\n","              \"    }\\n\",\n","              \"\\n\",\n","              \"    [theme=dark] .colab-df-convert:hover {\\n\",\n","              \"      background-color: #434B5C;\\n\",\n","              \"      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\\n\",\n","              \"      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\\n\",\n","              \"      fill: #FFFFFF;\\n\",\n","              \"    }\\n\",\n","              \"  </style>\\n\",\n","              \"\\n\",\n","              \"      <script>\\n\",\n","              \"        const buttonEl =\\n\",\n","              \"          document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b button.colab-df-convert');\\n\",\n","              \"        buttonEl.style.display =\\n\",\n","              \"          google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n","              \"\\n\",\n","              \"        async function convertToInteractive(key) {\\n\",\n","              \"          const element = document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b');\\n\",\n","              \"          const dataTable =\\n\",\n","              \"            await google.colab.kernel.invokeFunction('convertToInteractive',\\n\",\n","              \"                                                     [key], {});\\n\",\n","              \"          if (!dataTable) return;\\n\",\n","              \"\\n\",\n","              \"          const docLinkHtml = 'Like what you see? Visit the ' +\\n\",\n","              \"            '<a target=\\\"_blank\\\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\\n\",\n","              \"            + ' to learn more about interactive tables.';\\n\",\n","              \"          element.innerHTML = '';\\n\",\n","              \"          dataTable['output_type'] = 'display_data';\\n\",\n","              \"          await google.colab.output.renderOutput(dataTable, element);\\n\",\n","              \"          const docLink = document.createElement('div');\\n\",\n","              \"          docLink.innerHTML = docLinkHtml;\\n\",\n","              \"          element.appendChild(docLink);\\n\",\n","              \"        }\\n\",\n","              \"      </script>\\n\",\n","              \"    </div>\\n\",\n","              \"  </div>\\n\",\n","              \"  \"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 31\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        # \"device = torch.device(\\\"cuda\\\" if torch.cuda.is_available() else \\\"cpu\\\")\\n\",\n","        \"train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n\",\n","        \"#ÏúàÎèÑÏö∞ ÌôòÍ≤ΩÏóêÏÑú num_workers Îäî Î¨¥Ï°∞Í±¥ 0ÏúºÎ°ú ÏßÄÏ†ï, Î¶¨ÎàÖÏä§ÏóêÏÑúÎäî 2\\n\",\n","        \"train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"h8VN4b7MvE62\"\n","      },\n","      \"execution_count\": 32,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"model.to(device,dtype=torch.float64)\\n\",\n","        \"model.train()\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"3eHHvpkBvE9D\",\n","        \"outputId\": \"2547619f-4af3-4562-f940-0182371b8773\"\n","      },\n","      \"execution_count\": 35,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"GPT2LMHeadModel(\\n\",\n","              \"  (transformer): GPT2Model(\\n\",\n","              \"    (wte): Embedding(51200, 768)\\n\",\n","              \"    (wpe): Embedding(1024, 768)\\n\",\n","              \"    (drop): Dropout(p=0.1, inplace=False)\\n\",\n","              \"    (h): ModuleList(\\n\",\n","              \"      (0): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (1): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (2): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (3): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (4): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (5): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (6): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (7): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (8): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (9): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (10): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"      (11): GPT2Block(\\n\",\n","              \"        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (attn): GPT2Attention(\\n\",\n","              \"          (c_attn): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (attn_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"          (resid_dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"        (mlp): GPT2MLP(\\n\",\n","              \"          (c_fc): Conv1D()\\n\",\n","              \"          (c_proj): Conv1D()\\n\",\n","              \"          (act): NewGELUActivation()\\n\",\n","              \"          (dropout): Dropout(p=0.1, inplace=False)\\n\",\n","              \"        )\\n\",\n","              \"      )\\n\",\n","              \"    )\\n\",\n","              \"    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n\",\n","              \"  )\\n\",\n","              \"  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\\n\",\n","              \")\"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 35\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"learning_rate = 3e-5\\n\",\n","        \"criterion = torch.nn.CrossEntropyLoss(reduction=\\\"none\\\")\\n\",\n","        \"optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n\",\n","        \"\\n\",\n","        \"epoch = 10\\n\",\n","        \"Sneg = -1e18\"\n","      ],\n","      \"metadata\": {\n","        \"id\": \"KVXEFddFvtpc\"\n","      },\n","      \"execution_count\": 36,\n","      \"outputs\": []\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"print (\\\"start\\\")\\n\",\n","        \"for epoch in range(epoch):\\n\",\n","        \"    for batch_idx, samples in enumerate(train_dataloader):\\n\",\n","        \"        optimizer.zero_grad()\\n\",\n","        \"        token_ids, mask, label = samples\\n\",\n","        \"        out = model(token_ids).cuda()\\n\",\n","        \"        out = out.logits      #Returns a new tensor with the logit of the elements of input\\n\",\n","        \"        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\\n\",\n","        \"        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\\n\",\n","        \"        loss = criterion(mask_out.transpose(2, 1), label)\\n\",\n","        \"        # ÌèâÍ∑† loss ÎßåÎì§Í∏∞ avg_loss[0] / avg_loss[1] <- loss Ï†ïÍ∑úÌôî\\n\",\n","        \"        avg_loss = loss.sum() / mask.sum()\\n\",\n","        \"        avg_loss.backward()\\n\",\n","        \"        # ÌïôÏäµ ÎÅù\\n\",\n","        \"        optimizer.step()\\n\",\n","        \"print (\\\"end\\\")\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"4io3v7Puvtm-\",\n","        \"outputId\": \"2c99559f-497e-4b0a-e899-c75560364c91\"\n","      },\n","      \"execution_count\": 39,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"stream\",\n","          \"name\": \"stdout\",\n","          \"text\": [\n","            \"start\\n\",\n","            \"end\\n\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [\n","        \"with torch.no_grad():\\n\",\n","        \"    while 1:\\n\",\n","        \"        q = input(\\\"user > \\\").strip()\\n\",\n","        \"        if q == \\\"quit\\\":\\n\",\n","        \"            break\\n\",\n","        \"        a = \\\"\\\"\\n\",\n","        \"        while 1:\\n\",\n","        \"            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q  + A_TKN + a)).unsqueeze(dim=0)\\n\",\n","        \"            pred = model(input_ids).cuda()\\n\",\n","        \"            pred = pred.logits\\n\",\n","        \"            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\\n\",\n","        \"            if gen == EOS:\\n\",\n","        \"                break\\n\",\n","        \"            a += gen.replace(\\\"‚ñÅ\\\", \\\" \\\")\\n\",\n","        \"        print(\\\"Chatbot > {}\\\".format(a.strip()))\"\n","      ],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\",\n","          \"height\": 425\n","        },\n","        \"id\": \"85g8g8ZixeU8\",\n","        \"outputId\": \"16e51a16-e647-4b44-e217-2c0aa5c54215\"\n","      },\n","      \"execution_count\": 40,\n","      \"outputs\": [\n","        {\n","          \"name\": \"stdout\",\n","          \"output_type\": \"stream\",\n","          \"text\": [\n","            \"user > ÏïàÎÖïÌïòÏÑ∏Ïöî\\n\"\n","          ]\n","        },\n","        {\n","          \"output_type\": \"error\",\n","          \"ename\": \"RuntimeError\",\n","          \"evalue\": \"ignored\",\n","          \"traceback\": [\n","            \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n","            \"\\u001b[0;31mRuntimeError\\u001b[0m                              Traceback (most recent call last)\",\n","            \"\\u001b[0;32m<ipython-input-40-75429edffc48>\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m\\u001b[0m\\n\\u001b[1;32m      7\\u001b[0m         \\u001b[0;32mwhile\\u001b[0m \\u001b[0;36m1\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      8\\u001b[0m             \\u001b[0minput_ids\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mtorch\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mLongTensor\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkoGPT2_TOKENIZER\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mencode\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mQ_TKN\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0mq\\u001b[0m  \\u001b[0;34m+\\u001b[0m \\u001b[0mA_TKN\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0ma\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0munsqueeze\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mdim\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;36m0\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 9\\u001b[0;31m             \\u001b[0mpred\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mmodel\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0minput_ids\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m     10\\u001b[0m             \\u001b[0mpred\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mpred\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mlogits\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m     11\\u001b[0m             \\u001b[0mgen\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mkoGPT2_TOKENIZER\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mconvert_ids_to_tokens\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mtorch\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0margmax\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mpred\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mdim\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;34m-\\u001b[0m\\u001b[0;36m1\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0msqueeze\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mnumpy\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mtolist\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m[\\u001b[0m\\u001b[0;34m-\\u001b[0m\\u001b[0;36m1\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\u001b[0m in \\u001b[0;36m_call_impl\\u001b[0;34m(self, *input, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1128\\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\u001b[1;32m   1129\\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\u001b[0;32m-> 1130\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mforward_call\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1131\\u001b[0m         \\u001b[0;31m# Do not call functions when jit is used\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1132\\u001b[0m         \\u001b[0mfull_backward_hooks\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnon_full_backward_hooks\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\u001b[0m in \\u001b[0;36mforward\\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\\u001b[0m\\n\\u001b[1;32m   1044\\u001b[0m         \\u001b[0mreturn_dict\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mreturn_dict\\u001b[0m \\u001b[0;32mif\\u001b[0m \\u001b[0mreturn_dict\\u001b[0m \\u001b[0;32mis\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0;32mNone\\u001b[0m \\u001b[0;32melse\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mconfig\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0muse_return_dict\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1045\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 1046\\u001b[0;31m         transformer_outputs = self.transformer(\\n\\u001b[0m\\u001b[1;32m   1047\\u001b[0m             \\u001b[0minput_ids\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1048\\u001b[0m             \\u001b[0mpast_key_values\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0mpast_key_values\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\u001b[0m in \\u001b[0;36m_call_impl\\u001b[0;34m(self, *input, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1128\\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\u001b[1;32m   1129\\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\u001b[0;32m-> 1130\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mforward_call\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1131\\u001b[0m         \\u001b[0;31m# Do not call functions when jit is used\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1132\\u001b[0m         \\u001b[0mfull_backward_hooks\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnon_full_backward_hooks\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\u001b[0m in \\u001b[0;36mforward\\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\\u001b[0m\\n\\u001b[1;32m    830\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    831\\u001b[0m         \\u001b[0;32mif\\u001b[0m \\u001b[0minputs_embeds\\u001b[0m \\u001b[0;32mis\\u001b[0m \\u001b[0;32mNone\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 832\\u001b[0;31m             \\u001b[0minputs_embeds\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mwte\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0minput_ids\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    833\\u001b[0m         \\u001b[0mposition_embeds\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mwpe\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mposition_ids\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    834\\u001b[0m         \\u001b[0mhidden_states\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0minputs_embeds\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0mposition_embeds\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\u001b[0m in \\u001b[0;36m_call_impl\\u001b[0;34m(self, *input, **kwargs)\\u001b[0m\\n\\u001b[1;32m   1128\\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\u001b[1;32m   1129\\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\u001b[0;32m-> 1130\\u001b[0;31m             \\u001b[0;32mreturn\\u001b[0m \\u001b[0mforward_call\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m*\\u001b[0m\\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m**\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   1131\\u001b[0m         \\u001b[0;31m# Do not call functions when jit is used\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   1132\\u001b[0m         \\u001b[0mfull_backward_hooks\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnon_full_backward_hooks\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0;34m[\\u001b[0m\\u001b[0;34m]\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\\u001b[0m in \\u001b[0;36mforward\\u001b[0;34m(self, input)\\u001b[0m\\n\\u001b[1;32m    156\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    157\\u001b[0m     \\u001b[0;32mdef\\u001b[0m \\u001b[0mforward\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mself\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0minput\\u001b[0m\\u001b[0;34m:\\u001b[0m \\u001b[0mTensor\\u001b[0m\\u001b[0;34m)\\u001b[0m \\u001b[0;34m->\\u001b[0m \\u001b[0mTensor\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 158\\u001b[0;31m         return F.embedding(\\n\\u001b[0m\\u001b[1;32m    159\\u001b[0m             \\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mweight\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mpadding_idx\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0mmax_norm\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    160\\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\\n\",\n","            \"\\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\\u001b[0m in \\u001b[0;36membedding\\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\\u001b[0m\\n\\u001b[1;32m   2197\\u001b[0m         \\u001b[0;31m# remove once script supports set_grad_enabled\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2198\\u001b[0m         \\u001b[0m_no_grad_embedding_renorm_\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mweight\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mmax_norm\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mnorm_type\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 2199\\u001b[0;31m     \\u001b[0;32mreturn\\u001b[0m \\u001b[0mtorch\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0membedding\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mweight\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0minput\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mpadding_idx\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0mscale_grad_by_freq\\u001b[0m\\u001b[0;34m,\\u001b[0m \\u001b[0msparse\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m   2200\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2201\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n","            \"\\u001b[0;31mRuntimeError\\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)\"\n","          ]\n","        }\n","      ]\n","    },\n","    {\n","      \"cell_type\": \"code\",\n","      \"source\": [],\n","      \"metadata\": {\n","        \"colab\": {\n","          \"base_uri\": \"https://localhost:8080/\"\n","        },\n","        \"id\": \"QO5VC8WLyThv\",\n","        \"outputId\": \"169e4e53-4475-4c42-b58b-1b7b8263e59e\"\n","      },\n","      \"execution_count\": 38,\n","      \"outputs\": [\n","        {\n","          \"output_type\": \"execute_result\",\n","          \"data\": {\n","            \"text/plain\": [\n","              \"True\"\n","            ]\n","          },\n","          \"metadata\": {},\n","          \"execution_count\": 38\n","        }\n","      ]\n","    }\n","  ]\n","}"],"metadata":{"id":"0EBG5PNfpS8B","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670390521076,"user_tz":-540,"elapsed":328,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"ced7ac32-6b19-49c0-9056-6093d1c7062a"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'nbformat': 4,\n"," 'nbformat_minor': 0,\n"," 'metadata': {'colab': {'provenance': [], 'machine_shape': 'hm'},\n","  'kernelspec': {'name': 'python3', 'display_name': 'Python 3'},\n","  'language_info': {'name': 'python'},\n","  'accelerator': 'GPU',\n","  'gpuClass': 'standard'},\n"," 'cells': [{'cell_type': 'code',\n","   'source': ['!pip install transformers -q'],\n","   'metadata': {'id': 'Ax2iPY0JuKAC'},\n","   'execution_count': 6,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['# Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï≤òÎ¶¨ÌïòÎäî ÌÅ¥ÎûòÏä§Î•º ÎßåÎì†Îã§.\\n',\n","    'class ChatbotDataset(Dataset):\\n',\n","    '    def __init__(self, chats, max_len=40):  # Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Ï†ÑÏ≤òÎ¶¨Î•º Ìï¥Ï£ºÎäî Î∂ÄÎ∂Ñ\\n',\n","    '        self._data = chats\\n',\n","    '        self.max_len = max_len\\n',\n","    '        self.q_token = Q_TKN\\n',\n","    '        self.a_token = A_TKN\\n',\n","    '        self.sent_token = SENT\\n',\n","    '        self.eos = EOS\\n',\n","    '        self.mask = MASK\\n',\n","    '        self.tokenizer = koGPT2_TOKENIZER\\n',\n","    '\\n',\n","    '    def __len__(self):  # chatbotdata Ïùò Í∏∏Ïù¥Î•º Î¶¨ÌÑ¥ÌïúÎã§.\\n',\n","    '        return len(self._data)\\n',\n","    '\\n',\n","    '    def __getitem__(self, idx):  # Î°úÎìúÌïú Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï∞®Î°ÄÏ∞®Î°Ä DataLoaderÎ°ú ÎÑòÍ≤®Ï£ºÎäî Î©îÏÑúÎìú\\n',\n","    '        turn = self._data.iloc[idx]\\n',\n","    '        q = turn[\"Q\"]  # ÏßàÎ¨∏ÏùÑ Í∞ÄÏ†∏Ïò®Îã§.\\n',\n","    '        q = re.sub(r\"([?.!,])\", r\" \", q)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.\\n',\n","    '\\n',\n","    '        a = turn[\"A\"]  # ÎãµÎ≥ÄÏùÑ Í∞ÄÏ†∏Ïò®Îã§.\\n',\n","    '        a = re.sub(r\"([?.!,])\", r\" \", a)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.\\n',\n","    '\\n',\n","    '        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\\n',\n","    '        q_len = len(q_toked)\\n',\n","    '\\n',\n","    '        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\\n',\n","    '        a_len = len(a_toked)\\n',\n","    '\\n',\n","    '        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥\\n',\n","    '        if q_len > self.max_len:\\n',\n","    '            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n',\n","    '            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥\\n',\n","    '                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú \\n',\n","    '                q_len = len(q_toked)\\n',\n","    '                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n',\n","    '            a_toked = a_toked[:a_len]\\n',\n","    '            a_len = len(a_toked)\\n',\n","    '\\n',\n","    '        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥ + ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥\\n',\n","    '        if q_len + a_len > self.max_len:\\n',\n","    '            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n',\n","    '            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥\\n',\n","    '                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú \\n',\n","    '                q_len = len(q_toked)\\n',\n","    '                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\\n',\n","    '            a_toked = a_toked[:a_len]\\n',\n","    '            a_len = len(a_toked)\\n',\n","    '\\n',\n","    '        # ÎãµÎ≥Ä labels = [mask, mask, ...., mask, ..., <bos>,..ÎãµÎ≥Ä.. <eos>, <pad>....]\\n',\n","    '        labels = [self.mask,] * q_len + a_toked[1:]\\n',\n","    '\\n',\n","    '        # mask = ÏßàÎ¨∏Í∏∏Ïù¥ 0 + ÎãµÎ≥ÄÍ∏∏Ïù¥ 1 + ÎÇòÎ®∏ÏßÄ 0\\n',\n","    '        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\\n',\n","    '        # ÎãµÎ≥Ä labelsÏùÑ index Î°ú ÎßåÎì†Îã§.\\n',\n","    '        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\\n',\n","    '        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING\\n',\n","    '        while len(labels_ids) < self.max_len:\\n',\n","    '            labels_ids += [self.tokenizer.pad_token_id]\\n',\n","    '\\n',\n","    '        # ÏßàÎ¨∏ + ÎãµÎ≥ÄÏùÑ index Î°ú ÎßåÎì†Îã§.    \\n',\n","    '        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\\n',\n","    '        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING\\n',\n","    '        while len(token_ids) < self.max_len:\\n',\n","    '            token_ids += [self.tokenizer.pad_token_id]\\n',\n","    '\\n',\n","    '        #ÏßàÎ¨∏+ÎãµÎ≥Ä, ÎßàÏä§ÌÅ¨, ÎãµÎ≥Ä\\n',\n","    '        return (token_ids, np.array(mask), labels_ids)'],\n","   'metadata': {'id': 'wtSydcC3uJq0'},\n","   'execution_count': 7,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['def collate_batch(batch):\\n',\n","    '    data = [item[0] for item in batch]\\n',\n","    '    mask = [item[1] for item in batch]\\n',\n","    '    label = [item[2] for item in batch]\\n',\n","    '    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)'],\n","   'metadata': {'id': '7Eo3Lg5AuJuC'},\n","   'execution_count': 9,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n',\n","    '\\n',\n","    '#ÏúàÎèÑÏö∞ ÌôòÍ≤ΩÏóêÏÑú num_workers Îäî Î¨¥Ï°∞Í±¥ 0ÏúºÎ°ú ÏßÄÏ†ï, Î¶¨ÎàÖÏä§ÏóêÏÑúÎäî 2\\n',\n","    'train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)'],\n","   'metadata': {'id': 'HflM0VSJudYO'},\n","   'execution_count': 23,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['import torch\\n', 'from transformers import GPT2LMHeadModel'],\n","   'metadata': {'id': 'CxDjdgREvEjO'},\n","   'execution_count': 15,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['from transformers import PreTrainedTokenizerFast\\n',\n","    'tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\", bos_token=\\'</s>\\', eos_token=\\'</s>\\', unk_token=\\'<unk>\\', pad_token=\\'<pad>\\', mask_token=\\'<mask>\\') \\n',\n","    'tokenizer.tokenize(\"ÏïàÎÖïÌïòÏÑ∏Ïöî. ÌïúÍµ≠Ïñ¥ GPT-2 ÏûÖÎãàÎã§.üò§:)l^o\")'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': 'HGMBg0oWvEmG',\n","    'outputId': 'b83b9538-220c-41b9-a85a-091cd09606cd'},\n","   'execution_count': 16,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stderr',\n","     'text': ['The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n',\n","      \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","      \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"]},\n","    {'output_type': 'execute_result',\n","     'data': {'text/plain': [\"['‚ñÅÏïàÎÖï',\\n\",\n","       \" 'Ìïò',\\n\",\n","       \" 'ÏÑ∏',\\n\",\n","       \" 'Ïöî.',\\n\",\n","       \" '‚ñÅÌïúÍµ≠Ïñ¥',\\n\",\n","       \" '‚ñÅG',\\n\",\n","       \" 'P',\\n\",\n","       \" 'T',\\n\",\n","       \" '-2',\\n\",\n","       \" '‚ñÅÏûÖ',\\n\",\n","       \" 'ÎãàÎã§.',\\n\",\n","       \" 'üò§',\\n\",\n","       \" ':)',\\n\",\n","       \" 'l^o']\"]},\n","     'metadata': {},\n","     'execution_count': 16}]},\n","  {'cell_type': 'code',\n","   'source': ['!pip install pytorch_lightning -q'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': 'GcszoiwMvX4Y',\n","    'outputId': 'bf18fa61-232b-4fb0-c6d7-6325f673171d'},\n","   'execution_count': 1,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stdout',\n","     'text': ['Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\\n',\n","      'Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.8/dist-packages (1.8.3.post1)\\n',\n","      'Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\\n',\n","      'Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.1.1)\\n',\n","      'Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\\n',\n","      'Requirement already satisfied: lightning-utilities==0.3.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.3.0)\\n',\n","      'Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\\n',\n","      'Requirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.1+cu113)\\n',\n","      'Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (0.11.0)\\n',\n","      'Requirement already satisfied: tensorboardX>=2.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2.5.1)\\n',\n","      'Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\\n',\n","      'Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\\n',\n","      'Requirement already satisfied: fire in /usr/local/lib/python3.8/dist-packages (from lightning-utilities==0.3.*->pytorch_lightning) (0.4.0)\\n',\n","      'Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\\n',\n","      'Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\\n',\n","      'Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\\n',\n","      'Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\\n',\n","      'Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\\n',\n","      'Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\\n',\n","      'Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\\n',\n","      'Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\\n',\n","      'Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\\n',\n","      'Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\\n',\n","      'Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\\n',\n","      'Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\\n',\n","      'Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\\n',\n","      'Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.15.0)\\n',\n","      'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\\n',\n","      'Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\\n',\n","      'Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\\n']}]},\n","  {'cell_type': 'code',\n","   'source': ['import numpy as np\\n',\n","    'import pandas as pd\\n',\n","    'import torch\\n',\n","    'from pytorch_lightning import Trainer\\n',\n","    'from pytorch_lightning.callbacks import ModelCheckpoint\\n',\n","    'from pytorch_lightning.core.lightning import LightningModule\\n',\n","    'from torch.utils.data import DataLoader, Dataset\\n',\n","    'from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\\n',\n","    'from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\\n',\n","    'import re'],\n","   'metadata': {'id': 'GKeLSiYmvExD'},\n","   'execution_count': 28,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['Q_TKN = \"<usr>\"\\n',\n","    'A_TKN = \"<sys>\"\\n',\n","    \"BOS = '</s>'\\n\",\n","    \"EOS = '</s>'\\n\",\n","    \"MASK = '<unused0>'\\n\",\n","    \"SENT = '<unused1>'\\n\",\n","    \"PAD = '<pad>'\"],\n","   'metadata': {'id': '6uciWc48vEzr'},\n","   'execution_count': 29,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\\n',\n","    \"            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\\n\",\n","    '            pad_token=PAD, mask_token=MASK) \\n',\n","    \"model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\"],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': '9by9OEqrvE2K',\n","    'outputId': 'b49002e4-4f6d-48c1-9052-831070ac0117'},\n","   'execution_count': 30,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stderr',\n","     'text': ['The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \\n',\n","      \"The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \\n\",\n","      \"The class this function is called from is 'PreTrainedTokenizerFast'.\\n\"]}]},\n","  {'cell_type': 'code',\n","   'source': ['import urllib.request\\n',\n","    '\\n',\n","    'urllib.request.urlretrieve(\\n',\n","    '    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\\n',\n","    '    filename=\"ChatBotData.csv\",\\n',\n","    ')\\n',\n","    'Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\\n',\n","    '# Test Ïö©ÏúºÎ°ú 300Í∞ú Îç∞Ïù¥ÌÑ∞Îßå Ï≤òÎ¶¨ÌïúÎã§.\\n',\n","    'Chatbot_Data = Chatbot_Data[:300]\\n',\n","    'Chatbot_Data.head()'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/',\n","     'height': 206},\n","    'id': 'riP0GLx7vE4f',\n","    'outputId': 'c44e7367-4948-4def-bc8d-b6f4c54cb685'},\n","   'execution_count': 31,\n","   'outputs': [{'output_type': 'execute_result',\n","     'data': {'text/plain': ['                 Q            A  label\\n',\n","       '0           12Ïãú Îï°!   ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.      0\\n',\n","       '1      1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥    ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.      0\\n',\n","       '2     3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\\n',\n","       '3  3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§  Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.      0\\n',\n","       '4          PPL Ïã¨ÌïòÎÑ§   ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.      0'],\n","      'text/html': ['\\n',\n","       '  <div id=\"df-6907237d-e6c5-4927-95da-536fb96e400b\">\\n',\n","       '    <div class=\"colab-df-container\">\\n',\n","       '      <div>\\n',\n","       '<style scoped>\\n',\n","       '    .dataframe tbody tr th:only-of-type {\\n',\n","       '        vertical-align: middle;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .dataframe tbody tr th {\\n',\n","       '        vertical-align: top;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .dataframe thead th {\\n',\n","       '        text-align: right;\\n',\n","       '    }\\n',\n","       '</style>\\n',\n","       '<table border=\"1\" class=\"dataframe\">\\n',\n","       '  <thead>\\n',\n","       '    <tr style=\"text-align: right;\">\\n',\n","       '      <th></th>\\n',\n","       '      <th>Q</th>\\n',\n","       '      <th>A</th>\\n',\n","       '      <th>label</th>\\n',\n","       '    </tr>\\n',\n","       '  </thead>\\n',\n","       '  <tbody>\\n',\n","       '    <tr>\\n',\n","       '      <th>0</th>\\n',\n","       '      <td>12Ïãú Îï°!</td>\\n',\n","       '      <td>ÌïòÎ£®Í∞Ä Îòê Í∞ÄÎÑ§Ïöî.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>1</th>\\n',\n","       '      <td>1ÏßÄÎßù ÌïôÍµê Îñ®Ïñ¥Ï°åÏñ¥</td>\\n',\n","       '      <td>ÏúÑÎ°úÌï¥ ÎìúÎ¶ΩÎãàÎã§.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>2</th>\\n',\n","       '      <td>3Î∞ï4Ïùº ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\\n',\n","       '      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>3</th>\\n',\n","       '      <td>3Î∞ï4Ïùº Ï†ïÎèÑ ÎÜÄÎü¨Í∞ÄÍ≥† Ïã∂Îã§</td>\\n',\n","       '      <td>Ïó¨ÌñâÏùÄ Ïñ∏Ï†úÎÇò Ï¢ãÏ£†.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '    <tr>\\n',\n","       '      <th>4</th>\\n',\n","       '      <td>PPL Ïã¨ÌïòÎÑ§</td>\\n',\n","       '      <td>ÎààÏÇ¥Ïù¥ Ï∞åÌë∏Î†§ÏßÄÏ£†.</td>\\n',\n","       '      <td>0</td>\\n',\n","       '    </tr>\\n',\n","       '  </tbody>\\n',\n","       '</table>\\n',\n","       '</div>\\n',\n","       '      <button class=\"colab-df-convert\" onclick=\"convertToInteractive(\\'df-6907237d-e6c5-4927-95da-536fb96e400b\\')\"\\n',\n","       '              title=\"Convert this dataframe to an interactive table.\"\\n',\n","       '              style=\"display:none;\">\\n',\n","       '        \\n',\n","       '  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\\n',\n","       '       width=\"24px\">\\n',\n","       '    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\\n',\n","       '    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\\n',\n","       '  </svg>\\n',\n","       '      </button>\\n',\n","       '      \\n',\n","       '  <style>\\n',\n","       '    .colab-df-container {\\n',\n","       '      display:flex;\\n',\n","       '      flex-wrap:wrap;\\n',\n","       '      gap: 12px;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .colab-df-convert {\\n',\n","       '      background-color: #E8F0FE;\\n',\n","       '      border: none;\\n',\n","       '      border-radius: 50%;\\n',\n","       '      cursor: pointer;\\n',\n","       '      display: none;\\n',\n","       '      fill: #1967D2;\\n',\n","       '      height: 32px;\\n',\n","       '      padding: 0 0 0 0;\\n',\n","       '      width: 32px;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    .colab-df-convert:hover {\\n',\n","       '      background-color: #E2EBFA;\\n',\n","       '      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\\n',\n","       '      fill: #174EA6;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    [theme=dark] .colab-df-convert {\\n',\n","       '      background-color: #3B4455;\\n',\n","       '      fill: #D2E3FC;\\n',\n","       '    }\\n',\n","       '\\n',\n","       '    [theme=dark] .colab-df-convert:hover {\\n',\n","       '      background-color: #434B5C;\\n',\n","       '      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\\n',\n","       '      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\\n',\n","       '      fill: #FFFFFF;\\n',\n","       '    }\\n',\n","       '  </style>\\n',\n","       '\\n',\n","       '      <script>\\n',\n","       '        const buttonEl =\\n',\n","       \"          document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b button.colab-df-convert');\\n\",\n","       '        buttonEl.style.display =\\n',\n","       \"          google.colab.kernel.accessAllowed ? 'block' : 'none';\\n\",\n","       '\\n',\n","       '        async function convertToInteractive(key) {\\n',\n","       \"          const element = document.querySelector('#df-6907237d-e6c5-4927-95da-536fb96e400b');\\n\",\n","       '          const dataTable =\\n',\n","       \"            await google.colab.kernel.invokeFunction('convertToInteractive',\\n\",\n","       '                                                     [key], {});\\n',\n","       '          if (!dataTable) return;\\n',\n","       '\\n',\n","       \"          const docLinkHtml = 'Like what you see? Visit the ' +\\n\",\n","       '            \\'<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>\\'\\n',\n","       \"            + ' to learn more about interactive tables.';\\n\",\n","       \"          element.innerHTML = '';\\n\",\n","       \"          dataTable['output_type'] = 'display_data';\\n\",\n","       '          await google.colab.output.renderOutput(dataTable, element);\\n',\n","       \"          const docLink = document.createElement('div');\\n\",\n","       '          docLink.innerHTML = docLinkHtml;\\n',\n","       '          element.appendChild(docLink);\\n',\n","       '        }\\n',\n","       '      </script>\\n',\n","       '    </div>\\n',\n","       '  </div>\\n',\n","       '  ']},\n","     'metadata': {},\n","     'execution_count': 31}]},\n","  {'cell_type': 'code',\n","   'source': ['train_set = ChatbotDataset(Chatbot_Data, max_len=40)\\n',\n","    '#ÏúàÎèÑÏö∞ ÌôòÍ≤ΩÏóêÏÑú num_workers Îäî Î¨¥Ï°∞Í±¥ 0ÏúºÎ°ú ÏßÄÏ†ï, Î¶¨ÎàÖÏä§ÏóêÏÑúÎäî 2\\n',\n","    'train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)'],\n","   'metadata': {'id': 'h8VN4b7MvE62'},\n","   'execution_count': 32,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['model.to(device,dtype=torch.float64)\\n', 'model.train()'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': '3eHHvpkBvE9D',\n","    'outputId': '2547619f-4af3-4562-f940-0182371b8773'},\n","   'execution_count': 35,\n","   'outputs': [{'output_type': 'execute_result',\n","     'data': {'text/plain': ['GPT2LMHeadModel(\\n',\n","       '  (transformer): GPT2Model(\\n',\n","       '    (wte): Embedding(51200, 768)\\n',\n","       '    (wpe): Embedding(1024, 768)\\n',\n","       '    (drop): Dropout(p=0.1, inplace=False)\\n',\n","       '    (h): ModuleList(\\n',\n","       '      (0): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (1): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (2): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (3): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (4): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (5): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (6): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (7): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (8): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (9): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (10): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '      (11): GPT2Block(\\n',\n","       '        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (attn): GPT2Attention(\\n',\n","       '          (c_attn): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (attn_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '          (resid_dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '        (mlp): GPT2MLP(\\n',\n","       '          (c_fc): Conv1D()\\n',\n","       '          (c_proj): Conv1D()\\n',\n","       '          (act): NewGELUActivation()\\n',\n","       '          (dropout): Dropout(p=0.1, inplace=False)\\n',\n","       '        )\\n',\n","       '      )\\n',\n","       '    )\\n',\n","       '    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\\n',\n","       '  )\\n',\n","       '  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\\n',\n","       ')']},\n","     'metadata': {},\n","     'execution_count': 35}]},\n","  {'cell_type': 'code',\n","   'source': ['learning_rate = 3e-5\\n',\n","    'criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\\n',\n","    'optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n',\n","    '\\n',\n","    'epoch = 10\\n',\n","    'Sneg = -1e18'],\n","   'metadata': {'id': 'KVXEFddFvtpc'},\n","   'execution_count': 36,\n","   'outputs': []},\n","  {'cell_type': 'code',\n","   'source': ['print (\"start\")\\n',\n","    'for epoch in range(epoch):\\n',\n","    '    for batch_idx, samples in enumerate(train_dataloader):\\n',\n","    '        optimizer.zero_grad()\\n',\n","    '        token_ids, mask, label = samples\\n',\n","    '        out = model(token_ids).cuda()\\n',\n","    '        out = out.logits      #Returns a new tensor with the logit of the elements of input\\n',\n","    '        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\\n',\n","    '        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\\n',\n","    '        loss = criterion(mask_out.transpose(2, 1), label)\\n',\n","    '        # ÌèâÍ∑† loss ÎßåÎì§Í∏∞ avg_loss[0] / avg_loss[1] <- loss Ï†ïÍ∑úÌôî\\n',\n","    '        avg_loss = loss.sum() / mask.sum()\\n',\n","    '        avg_loss.backward()\\n',\n","    '        # ÌïôÏäµ ÎÅù\\n',\n","    '        optimizer.step()\\n',\n","    'print (\"end\")'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': '4io3v7Puvtm-',\n","    'outputId': '2c99559f-497e-4b0a-e899-c75560364c91'},\n","   'execution_count': 39,\n","   'outputs': [{'output_type': 'stream',\n","     'name': 'stdout',\n","     'text': ['start\\n', 'end\\n']}]},\n","  {'cell_type': 'code',\n","   'source': ['with torch.no_grad():\\n',\n","    '    while 1:\\n',\n","    '        q = input(\"user > \").strip()\\n',\n","    '        if q == \"quit\":\\n',\n","    '            break\\n',\n","    '        a = \"\"\\n',\n","    '        while 1:\\n',\n","    '            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q  + A_TKN + a)).unsqueeze(dim=0)\\n',\n","    '            pred = model(input_ids).cuda()\\n',\n","    '            pred = pred.logits\\n',\n","    '            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\\n',\n","    '            if gen == EOS:\\n',\n","    '                break\\n',\n","    '            a += gen.replace(\"‚ñÅ\", \" \")\\n',\n","    '        print(\"Chatbot > {}\".format(a.strip()))'],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/',\n","     'height': 425},\n","    'id': '85g8g8ZixeU8',\n","    'outputId': '16e51a16-e647-4b44-e217-2c0aa5c54215'},\n","   'execution_count': 40,\n","   'outputs': [{'name': 'stdout',\n","     'output_type': 'stream',\n","     'text': ['user > ÏïàÎÖïÌïòÏÑ∏Ïöî\\n']},\n","    {'output_type': 'error',\n","     'ename': 'RuntimeError',\n","     'evalue': 'ignored',\n","     'traceback': ['\\x1b[0;31m---------------------------------------------------------------------------\\x1b[0m',\n","      '\\x1b[0;31mRuntimeError\\x1b[0m                              Traceback (most recent call last)',\n","      '\\x1b[0;32m<ipython-input-40-75429edffc48>\\x1b[0m in \\x1b[0;36m<module>\\x1b[0;34m\\x1b[0m\\n\\x1b[1;32m      7\\x1b[0m         \\x1b[0;32mwhile\\x1b[0m \\x1b[0;36m1\\x1b[0m\\x1b[0;34m:\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m      8\\x1b[0m             \\x1b[0minput_ids\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mtorch\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mLongTensor\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mkoGPT2_TOKENIZER\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mencode\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mQ_TKN\\x1b[0m \\x1b[0;34m+\\x1b[0m \\x1b[0mq\\x1b[0m  \\x1b[0;34m+\\x1b[0m \\x1b[0mA_TKN\\x1b[0m \\x1b[0;34m+\\x1b[0m \\x1b[0ma\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0munsqueeze\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mdim\\x1b[0m\\x1b[0;34m=\\x1b[0m\\x1b[0;36m0\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m----> 9\\x1b[0;31m             \\x1b[0mpred\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mmodel\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0minput_ids\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m     10\\x1b[0m             \\x1b[0mpred\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mpred\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mlogits\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m     11\\x1b[0m             \\x1b[0mgen\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mkoGPT2_TOKENIZER\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mconvert_ids_to_tokens\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mtorch\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0margmax\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mpred\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mdim\\x1b[0m\\x1b[0;34m=\\x1b[0m\\x1b[0;34m-\\x1b[0m\\x1b[0;36m1\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0msqueeze\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mnumpy\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mtolist\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m[\\x1b[0m\\x1b[0;34m-\\x1b[0m\\x1b[0;36m1\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\x1b[0m in \\x1b[0;36m_call_impl\\x1b[0;34m(self, *input, **kwargs)\\x1b[0m\\n\\x1b[1;32m   1128\\x1b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\x1b[1;32m   1129\\x1b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\x1b[0;32m-> 1130\\x1b[0;31m             \\x1b[0;32mreturn\\x1b[0m \\x1b[0mforward_call\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m*\\x1b[0m\\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m**\\x1b[0m\\x1b[0mkwargs\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   1131\\x1b[0m         \\x1b[0;31m# Do not call functions when jit is used\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1132\\x1b[0m         \\x1b[0mfull_backward_hooks\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnon_full_backward_hooks\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\x1b[0m in \\x1b[0;36mforward\\x1b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, use_cache, output_attentions, output_hidden_states, return_dict)\\x1b[0m\\n\\x1b[1;32m   1044\\x1b[0m         \\x1b[0mreturn_dict\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mreturn_dict\\x1b[0m \\x1b[0;32mif\\x1b[0m \\x1b[0mreturn_dict\\x1b[0m \\x1b[0;32mis\\x1b[0m \\x1b[0;32mnot\\x1b[0m \\x1b[0;32mNone\\x1b[0m \\x1b[0;32melse\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mconfig\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0muse_return_dict\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1045\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m-> 1046\\x1b[0;31m         transformer_outputs = self.transformer(\\n\\x1b[0m\\x1b[1;32m   1047\\x1b[0m             \\x1b[0minput_ids\\x1b[0m\\x1b[0;34m,\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1048\\x1b[0m             \\x1b[0mpast_key_values\\x1b[0m\\x1b[0;34m=\\x1b[0m\\x1b[0mpast_key_values\\x1b[0m\\x1b[0;34m,\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\x1b[0m in \\x1b[0;36m_call_impl\\x1b[0;34m(self, *input, **kwargs)\\x1b[0m\\n\\x1b[1;32m   1128\\x1b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\x1b[1;32m   1129\\x1b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\x1b[0;32m-> 1130\\x1b[0;31m             \\x1b[0;32mreturn\\x1b[0m \\x1b[0mforward_call\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m*\\x1b[0m\\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m**\\x1b[0m\\x1b[0mkwargs\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   1131\\x1b[0m         \\x1b[0;31m# Do not call functions when jit is used\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1132\\x1b[0m         \\x1b[0mfull_backward_hooks\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnon_full_backward_hooks\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/transformers/models/gpt2/modeling_gpt2.py\\x1b[0m in \\x1b[0;36mforward\\x1b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\\x1b[0m\\n\\x1b[1;32m    830\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    831\\x1b[0m         \\x1b[0;32mif\\x1b[0m \\x1b[0minputs_embeds\\x1b[0m \\x1b[0;32mis\\x1b[0m \\x1b[0;32mNone\\x1b[0m\\x1b[0;34m:\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m--> 832\\x1b[0;31m             \\x1b[0minputs_embeds\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mwte\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0minput_ids\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m    833\\x1b[0m         \\x1b[0mposition_embeds\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mwpe\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mposition_ids\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    834\\x1b[0m         \\x1b[0mhidden_states\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0minputs_embeds\\x1b[0m \\x1b[0;34m+\\x1b[0m \\x1b[0mposition_embeds\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\\x1b[0m in \\x1b[0;36m_call_impl\\x1b[0;34m(self, *input, **kwargs)\\x1b[0m\\n\\x1b[1;32m   1128\\x1b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\\n\\x1b[1;32m   1129\\x1b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\\n\\x1b[0;32m-> 1130\\x1b[0;31m             \\x1b[0;32mreturn\\x1b[0m \\x1b[0mforward_call\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0;34m*\\x1b[0m\\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m**\\x1b[0m\\x1b[0mkwargs\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   1131\\x1b[0m         \\x1b[0;31m# Do not call functions when jit is used\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   1132\\x1b[0m         \\x1b[0mfull_backward_hooks\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnon_full_backward_hooks\\x1b[0m \\x1b[0;34m=\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0;34m[\\x1b[0m\\x1b[0;34m]\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/sparse.py\\x1b[0m in \\x1b[0;36mforward\\x1b[0;34m(self, input)\\x1b[0m\\n\\x1b[1;32m    156\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    157\\x1b[0m     \\x1b[0;32mdef\\x1b[0m \\x1b[0mforward\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mself\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0minput\\x1b[0m\\x1b[0;34m:\\x1b[0m \\x1b[0mTensor\\x1b[0m\\x1b[0;34m)\\x1b[0m \\x1b[0;34m->\\x1b[0m \\x1b[0mTensor\\x1b[0m\\x1b[0;34m:\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m--> 158\\x1b[0;31m         return F.embedding(\\n\\x1b[0m\\x1b[1;32m    159\\x1b[0m             \\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mweight\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mpadding_idx\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mself\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0mmax_norm\\x1b[0m\\x1b[0;34m,\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m    160\\x1b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\\n',\n","      '\\x1b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\\x1b[0m in \\x1b[0;36membedding\\x1b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\\x1b[0m\\n\\x1b[1;32m   2197\\x1b[0m         \\x1b[0;31m# remove once script supports set_grad_enabled\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   2198\\x1b[0m         \\x1b[0m_no_grad_embedding_renorm_\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mweight\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mmax_norm\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mnorm_type\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0;32m-> 2199\\x1b[0;31m     \\x1b[0;32mreturn\\x1b[0m \\x1b[0mtorch\\x1b[0m\\x1b[0;34m.\\x1b[0m\\x1b[0membedding\\x1b[0m\\x1b[0;34m(\\x1b[0m\\x1b[0mweight\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0minput\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mpadding_idx\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0mscale_grad_by_freq\\x1b[0m\\x1b[0;34m,\\x1b[0m \\x1b[0msparse\\x1b[0m\\x1b[0;34m)\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[0m\\x1b[1;32m   2200\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n\\x1b[1;32m   2201\\x1b[0m \\x1b[0;34m\\x1b[0m\\x1b[0m\\n',\n","      '\\x1b[0;31mRuntimeError\\x1b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper__index_select)']}]},\n","  {'cell_type': 'code',\n","   'source': [],\n","   'metadata': {'colab': {'base_uri': 'https://localhost:8080/'},\n","    'id': 'QO5VC8WLyThv',\n","    'outputId': '169e4e53-4475-4c42-b58b-1b7b8263e59e'},\n","   'execution_count': 38,\n","   'outputs': [{'output_type': 'execute_result',\n","     'data': {'text/plain': ['True']},\n","     'metadata': {},\n","     'execution_count': 38}]}]}"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["!pip install transformers -q"],"metadata":{"id":"nKj9W1DApS5r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670390145117,"user_tz":-540,"elapsed":9535,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"4c037362-3614-4c1a-9ee5-a958073ad523"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.8 MB 5.0 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 69.4 MB/s \n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 182 kB 81.2 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["import math\n","import numpy as np\n","import pandas as pd\n","import random\n","import re\n","import torch\n","import urllib.request\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import PreTrainedTokenizerFast"],"metadata":{"id":"pRofYonM4OG2","executionInfo":{"status":"ok","timestamp":1670390164258,"user_tz":-540,"elapsed":4247,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!pip install pytorch_lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GPbgLfsx4o6k","executionInfo":{"status":"ok","timestamp":1670390152852,"user_tz":-540,"elapsed":7744,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"18978f98-9799-4bc7-d8a0-c27b06eb13ff"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-1.8.3.post1-py3-none-any.whl (798 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 798 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (2022.11.0)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.0-py3-none-any.whl (512 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 512 kB 92.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.1.1)\n","Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (21.3)\n","Collecting lightning-utilities==0.3.*\n","  Downloading lightning_utilities-0.3.0-py3-none-any.whl (15 kB)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (6.0)\n","Collecting tensorboardX>=2.2\n","  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 125 kB 56.5 MB/s \n","\u001b[?25hRequirement already satisfied: torch>=1.9.* in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.12.1+cu113)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (1.21.6)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch_lightning) (4.64.1)\n","Collecting fire\n","  Downloading fire-0.4.0.tar.gz (87 kB)\n","\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 87 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.23.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.8.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (22.1.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.9)\n","Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorboardX>=2.2->pytorch_lightning) (3.19.6)\n","Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.8/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from fire->lightning-utilities==0.3.*->pytorch_lightning) (2.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.24.3)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115943 sha256=8df824abcb6437e0923e9487751ce6b8579cbd55daf5230b6789c6f6223d9743\n","  Stored in directory: /root/.cache/pip/wheels/1f/10/06/2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n","Successfully built fire\n","Installing collected packages: fire, torchmetrics, tensorboardX, lightning-utilities, pytorch-lightning\n","Successfully installed fire-0.4.0 lightning-utilities-0.3.0 pytorch-lightning-1.8.3.post1 tensorboardX-2.5.1 torchmetrics-0.11.0\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","from pytorch_lightning import Trainer\n","from pytorch_lightning.callbacks import ModelCheckpoint\n","from pytorch_lightning.core.lightning import LightningModule\n","from torch.utils.data import DataLoader, Dataset\n","from transformers.optimization import AdamW, get_cosine_schedule_with_warmup\n","from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel\n","import re"],"metadata":{"id":"7HCJPABx4-HO","executionInfo":{"status":"ok","timestamp":1670390175814,"user_tz":-540,"elapsed":555,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["Q_TKN = \"<usr>\"\n","A_TKN = \"<sys>\"\n","BOS = '</s>'\n","EOS = '</s>'\n","MASK = '<unused0>'\n","SENT = '<unused1>'\n","PAD = '<pad>'"],"metadata":{"id":"Wy3wj1ak4uNY","executionInfo":{"status":"ok","timestamp":1670390180273,"user_tz":-540,"elapsed":2,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["koGPT2_TOKENIZER = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\",\n","            bos_token=BOS, eos_token=EOS, unk_token='<unk>',\n","            pad_token=PAD, mask_token=MASK) \n","model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["529d0bd240124ad0996beb37b84df0c4","a4409363d601444080dc231d66ac04f9","2f1d96ea89f64c02859f552513f82569","2009ae2d8659480ba38e2b52bd50b785","99fd91bd21dc424cb125b8bf82103060","2870d1f79d0a4c269b2013c5ae04207e","e18cd0870770401998906f5ae942656c","07485e67417a49d1b5991cc7dd93f9ad","796a8f17426d47b2a98f4c4b114449d9","2c974a4d736e4e0aa8fb2e1df8dfaeab","295f636c11ec4986ba5e6881d72dfd18","36ff5032b1794d7da83f50b83b6a1028","be485e1609a8482b88f3df0e2f2a5b95","ad1f4688080140b2a20cbf1f6181799e","31502d43ca5a45d0b70dc48e0ced499b","5365579db72b479f90d9685ecdc74147","7411adacb2f3470ab8263e0c06cefa82","0df0ccdf19e94451b4145bd87c5f69e8","44e1d7882c7b42309ef68716b3e6196a","03afb31c12ce4f16ae09aed113841922","f35e313cc3734264bfb68116284cda4d","7a3085ace50b4999b8484a02ee6d574b","06731cf712ea4e1ca8102ef493ad3d7b","ecdddbfa4053423c8144e3a9f6b87bf3","f55b22ff46da49e2b9fd805bb3cd6cd3","70caf097c22e4729a849c7bfea8d7c35","349af36cef2c40329b54da9b5abf20be","78309c57a9d448a5926233889db761e7","869107e0430f4568b223c5e319b85f3e","595929dc195449c5b76c630716d07135","e424ba393b9f44119c3d429ab82ce936","e6a3ee1c1dbe42fdaae7a0d69d348f3d","088c7fe8517643c09348444dd8ac1a51"]},"id":"VVD1JqTJ40I9","executionInfo":{"status":"ok","timestamp":1670390207984,"user_tz":-540,"elapsed":25788,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"6a656759-517c-44ff-82b3-e6bd8ac9a58d"},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"529d0bd240124ad0996beb37b84df0c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36ff5032b1794d7da83f50b83b6a1028"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n","The class this function is called from is 'PreTrainedTokenizerFast'.\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/513M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06731cf712ea4e1ca8102ef493ad3d7b"}},"metadata":{}}]},{"cell_type":"code","source":["# Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï≤òÎ¶¨ÌïòÎäî ÌÅ¥ÎûòÏä§Î•º ÎßåÎì†Îã§.\n","class ChatbotDataset(Dataset):\n","    def __init__(self, chats, max_len=40):  # Îç∞Ïù¥ÌÑ∞ÏÖãÏùò Ï†ÑÏ≤òÎ¶¨Î•º Ìï¥Ï£ºÎäî Î∂ÄÎ∂Ñ\n","        self._data = chats\n","        self.max_len = max_len\n","        self.q_token = Q_TKN\n","        self.a_token = A_TKN\n","        self.sent_token = SENT\n","        self.eos = EOS\n","        self.mask = MASK\n","        self.tokenizer = koGPT2_TOKENIZER\n","\n","    def __len__(self):  # chatbotdata Ïùò Í∏∏Ïù¥Î•º Î¶¨ÌÑ¥ÌïúÎã§.\n","        return len(self._data)\n","\n","    def __getitem__(self, idx):  # Î°úÎìúÌïú Ï±óÎ¥á Îç∞Ïù¥ÌÑ∞Î•º Ï∞®Î°ÄÏ∞®Î°Ä DataLoaderÎ°ú ÎÑòÍ≤®Ï£ºÎäî Î©îÏÑúÎìú\n","        turn = self._data.iloc[idx]\n","        q = turn[\"Q\"]  # ÏßàÎ¨∏ÏùÑ Í∞ÄÏ†∏Ïò®Îã§.\n","        q = re.sub(r\"([?.!,])\", r\" \", q)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.\n","\n","        a = turn[\"A\"]  # ÎãµÎ≥ÄÏùÑ Í∞ÄÏ†∏Ïò®Îã§.\n","        a = re.sub(r\"([?.!,])\", r\" \", a)  # Íµ¨Îë£Ï†êÎì§ÏùÑ Ï†úÍ±∞ÌïúÎã§.\n","\n","        q_toked = self.tokenizer.tokenize(self.q_token + q + self.sent_token)\n","        q_len = len(q_toked)\n","\n","        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n","        a_len = len(a_toked)\n","\n","        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥\n","        if q_len > self.max_len:\n","            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\n","            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥ + ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Í∞Ä ÏµúÎåÄÍ∏∏Ïù¥Î≥¥Îã§ ÌÅ¨Î©¥\n","        if q_len + a_len > self.max_len:\n","            a_len = self.max_len - q_len        #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\n","            if a_len <= 0:       #ÏßàÎ¨∏Ïùò Í∏∏Ïù¥Í∞Ä ÎÑàÎ¨¥ Í∏∏Ïñ¥ ÏßàÎ¨∏ÎßåÏúºÎ°ú ÏµúÎåÄ Í∏∏Ïù¥Î•º Ï¥àÍ≥º ÌïúÎã§Î©¥\n","                q_toked = q_toked[-(int(self.max_len / 2)) :]   #ÏßàÎ¨∏Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥Ïùò Î∞òÏúºÎ°ú \n","                q_len = len(q_toked)\n","                a_len = self.max_len - q_len              #ÎãµÎ≥ÄÏùò Í∏∏Ïù¥Î•º ÏµúÎåÄÍ∏∏Ïù¥ - ÏßàÎ¨∏Í∏∏Ïù¥\n","            a_toked = a_toked[:a_len]\n","            a_len = len(a_toked)\n","\n","        # ÎãµÎ≥Ä labels = [mask, mask, ...., mask, ..., <bos>,..ÎãµÎ≥Ä.. <eos>, <pad>....]\n","        labels = [self.mask,] * q_len + a_toked[1:]\n","\n","        # mask = ÏßàÎ¨∏Í∏∏Ïù¥ 0 + ÎãµÎ≥ÄÍ∏∏Ïù¥ 1 + ÎÇòÎ®∏ÏßÄ 0\n","        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n","        # ÎãµÎ≥Ä labelsÏùÑ index Î°ú ÎßåÎì†Îã§.\n","        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n","        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING\n","        while len(labels_ids) < self.max_len:\n","            labels_ids += [self.tokenizer.pad_token_id]\n","\n","        # ÏßàÎ¨∏ + ÎãµÎ≥ÄÏùÑ index Î°ú ÎßåÎì†Îã§.    \n","        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n","        # ÏµúÎåÄÍ∏∏Ïù¥ÎßåÌÅº PADDING\n","        while len(token_ids) < self.max_len:\n","            token_ids += [self.tokenizer.pad_token_id]\n","\n","        #ÏßàÎ¨∏+ÎãµÎ≥Ä, ÎßàÏä§ÌÅ¨, ÎãµÎ≥Ä\n","        return (token_ids, np.array(mask), labels_ids)"],"metadata":{"id":"vkAHvUKP4QAn","executionInfo":{"status":"ok","timestamp":1670390207985,"user_tz":-540,"elapsed":10,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def collate_batch(batch):\n","    data = [item[0] for item in batch]\n","    mask = [item[1] for item in batch]\n","    label = [item[2] for item in batch]\n","    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)"],"metadata":{"id":"4YmgAlnB4Rgn","executionInfo":{"status":"ok","timestamp":1670390207986,"user_tz":-540,"elapsed":8,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Îç∞Ïù¥ÌÑ∞ÏÖã Î∂àÎü¨Ïò§Îäî Î∂ÄÎ∂Ñ\n","import urllib.request\n","\n","urllib.request.urlretrieve(\n","    \"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\",\n","    filename=\"ChatBotData.csv\",\n",")\n","Chatbot_Data = pd.read_csv(\"ChatBotData.csv\")\n","\n","# Test Ïö©ÏúºÎ°ú 300Í∞ú Îç∞Ïù¥ÌÑ∞Îßå Ï≤òÎ¶¨ÌïúÎã§.\n","# Chatbot_Data = Chatbot_Data[:300]\n","# Chatbot_Data.head(20)"],"metadata":{"id":"pOuW4Tiw4TD4","executionInfo":{"status":"ok","timestamp":1670378186891,"user_tz":-540,"elapsed":1589,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data = pd.read_csv(\"totaldf.csv\")"],"metadata":{"id":"bbnz6g_kAlYT","executionInfo":{"status":"ok","timestamp":1670390207986,"user_tz":-540,"elapsed":7,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.drop('label',axis=1,inplace=True)"],"metadata":{"id":"22CmS2M8TG9A","executionInfo":{"status":"ok","timestamp":1670378217497,"user_tz":-540,"elapsed":9,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data[Chatbot_Data['Q'].str.contains('Ï†êÏã¨')]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":551},"id":"Dzn0ZTmwwd4m","executionInfo":{"status":"ok","timestamp":1670289165727,"user_tz":-540,"elapsed":321,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"da7e2248-e9db-42de-b7ba-9d9ec3da2896"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                   Q                       A  label\n","3310                     Ïò§Îäò Ï†êÏã¨ Î≠ê Î®πÏùÑÍπå               ÎÉâÎ©¥ÏùÄ Ïñ¥Îñ†ÏÑ∏Ïöî?      0\n","3311                          Ïò§Îäò Ï†êÏã¨ÏùÄ     ÎÇ†Ïî®ÎèÑ Ï∂îÏö¥Îç∞ Îú®ÎÅàÌïú Íµ≠Î¨º ÎìúÏÑ∏Ïöî!      0\n","4116                 Ï†êÏã¨ ÎèÑÏãúÎùΩ Ïã∏Îäî Í±∞ Í∑ÄÏ∞ÆÎã§     Í±¥Í∞ïÏùÑ Ï±ôÍ∏¥Îã§Îäî ÎßàÏùåÏúºÎ°ú Ìï¥Î≥¥ÏÑ∏Ïöî.      0\n","4117                   Ï†êÏã¨ Îïå ÏùÄÌñâ Í∞îÎã§ÏôÄÏïºÏßÄ              Î≥º ÏùºÏù¥ ÏûàÎÇòÎ¥êÏöî.      0\n","4118                         Ï†êÏã¨ Î®πÏñ¥ÏïºÏßÄ       Ï¶êÍ±∞Ïö¥ ÏãúÍ∞Ñ Î≥¥ÎÇ¥ÏãúÍ∏∏ Î∞îÎûçÎãàÎã§.      0\n","4119                 Ï†êÏã¨ Î©îÎâ¥ Í≥†Î•¥Îäî Í±∞ ÌûòÎìúÎÑ§          ÎßûÏïÑÏöî Ìï≠ÏÉÅ Í≥†ÎØºÏù¥ ÎêòÏ£†.      0\n","4120                     Ï†êÏã¨ Î©îÎâ¥ Ï¢Ä Í≥®ÎùºÏ§ò  Ï£ºÎ≥Ä Î∂ÑÎì§Ïùò ÏñòÍ∏∞Î•º Îì§Ïñ¥Î≥¥ÎäîÍ±¥ Ïñ¥Îñ®ÍπåÏöî?      0\n","4121                      Ï†êÏã¨ÏãúÍ∞Ñ ÎÑàÎ¨¥ ÏßßÏïÑ             ÏùºÌïòÎäî ÏãúÍ∞ÑÏùÄ Í∏∏Ï£†.      0\n","4122             Ï†êÏã¨ÏãúÍ∞ÑÏóê Ïô∏Ï∂úÌïòÎäî Í≤ÉÎèÑ ÎààÏπòÎ¥êÏïºÎèº     Ï†ïÎßê ÎÑàÎ¨¥ÌïòÎÑ§Ïöî Í∞úÏù∏Ï†ÅÏù∏ ÏãúÍ∞ÑÏù∏Îç∞.      0\n","4123                 Ï†êÏã¨ÏãúÍ∞ÑÏóê Ïô∏Ï∂úÌïòÎ©¥ Ïïà ÎêòÎÇò         ÏãúÍ∞ÑÏïàÏóêÎßå Ïò®Îã§Î©¥ Í∞ÄÎä•ÌïòÏ£†.      0\n","4124                  Ï†êÏã¨ÏãúÍ∞ÑÏóê ÏùÄÌñâ Í∞îÎã§ÏôÄÏïºÏßÄ              Î≥º ÏùºÏù¥ ÏûàÎÇòÎ¥êÏöî.      0\n","4125                  Ï†êÏã¨ÏãúÍ∞ÑÏóî Í∑∏ÎÉ• Ïâ¨Í≥† Ïã∂Ïñ¥  ÎßõÎÇúÍ±∞ ÎìúÏãúÍ≥† Ï°∞Í∏àÏù¥ÎùºÎèÑ Ïâ¨ÏÖîÏïº Ìï†ÌÖêÎç∞.      0\n","4126             Ï†êÏã¨ÏãúÍ∞ÑÏù¥ÎùºÎèÑ ÎßàÏùå ÎÜìÍ≥† Ïâ¨Í≥† Ïã∂Ïñ¥  ÎßõÎÇúÍ±∞ ÎìúÏãúÍ≥† Ï°∞Í∏àÏù¥ÎùºÎèÑ Ïâ¨ÏÖîÏïº Ìï†ÌÖêÎç∞.      0\n","7700     Ïù¥Ï†ú Ï†êÏã¨ÏãúÍ∞ÑÏóêÎèÑ ÎÑàÏóêÍ≤å Ïπ¥ÌÜ°ÏùÑ Ìï† ÏàòÍ∞Ä ÏóÜÍµ¨ÎÇò.  Ï†êÏã¨ÏãúÍ∞ÑÏóê Ìï† Ïàò ÏûàÎäî Îã§Î•∏ Í±∏ Ìï¥Î¥êÏöî.      1\n","8008   Ï†êÏã¨ÏãúÍ∞ÑÏû†Íπê Í∑∏ÎÖÄÍ∞Ä Ï†ÄÏóêÍ≤å ÌñàÎçò ÎßêÎì§Ïù¥ Îñ†Ïò§Î•¥ÎÑ§~„Ö†„Ö†       ÏÉùÍ∞ÅÏùÑ Ï†ëÏñ¥ÎëêÎäî Í≤ÉÎèÑ ÌïÑÏöîÌï¥Ïöî.      1\n","11002              Ï†êÏã¨ÏãúÍ∞ÑÏùº ÌÖêÎç∞ Ïπ¥ÌÜ°Ïù¥ Ïïà ÏôÄ.      Î®ºÏ†Ä Ïó∞ÎùΩÏùÑ Ìï¥Î≥¥Îäî Í±¥ Ïñ¥Îñ®ÍπåÏöî?      2"],"text/html":["\n","  <div id=\"df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3310</th>\n","      <td>Ïò§Îäò Ï†êÏã¨ Î≠ê Î®πÏùÑÍπå</td>\n","      <td>ÎÉâÎ©¥ÏùÄ Ïñ¥Îñ†ÏÑ∏Ïöî?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3311</th>\n","      <td>Ïò§Îäò Ï†êÏã¨ÏùÄ</td>\n","      <td>ÎÇ†Ïî®ÎèÑ Ï∂îÏö¥Îç∞ Îú®ÎÅàÌïú Íµ≠Î¨º ÎìúÏÑ∏Ïöî!</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4116</th>\n","      <td>Ï†êÏã¨ ÎèÑÏãúÎùΩ Ïã∏Îäî Í±∞ Í∑ÄÏ∞ÆÎã§</td>\n","      <td>Í±¥Í∞ïÏùÑ Ï±ôÍ∏¥Îã§Îäî ÎßàÏùåÏúºÎ°ú Ìï¥Î≥¥ÏÑ∏Ïöî.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4117</th>\n","      <td>Ï†êÏã¨ Îïå ÏùÄÌñâ Í∞îÎã§ÏôÄÏïºÏßÄ</td>\n","      <td>Î≥º ÏùºÏù¥ ÏûàÎÇòÎ¥êÏöî.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4118</th>\n","      <td>Ï†êÏã¨ Î®πÏñ¥ÏïºÏßÄ</td>\n","      <td>Ï¶êÍ±∞Ïö¥ ÏãúÍ∞Ñ Î≥¥ÎÇ¥ÏãúÍ∏∏ Î∞îÎûçÎãàÎã§.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4119</th>\n","      <td>Ï†êÏã¨ Î©îÎâ¥ Í≥†Î•¥Îäî Í±∞ ÌûòÎìúÎÑ§</td>\n","      <td>ÎßûÏïÑÏöî Ìï≠ÏÉÅ Í≥†ÎØºÏù¥ ÎêòÏ£†.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4120</th>\n","      <td>Ï†êÏã¨ Î©îÎâ¥ Ï¢Ä Í≥®ÎùºÏ§ò</td>\n","      <td>Ï£ºÎ≥Ä Î∂ÑÎì§Ïùò ÏñòÍ∏∞Î•º Îì§Ïñ¥Î≥¥ÎäîÍ±¥ Ïñ¥Îñ®ÍπåÏöî?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4121</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞Ñ ÎÑàÎ¨¥ ÏßßÏïÑ</td>\n","      <td>ÏùºÌïòÎäî ÏãúÍ∞ÑÏùÄ Í∏∏Ï£†.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4122</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏóê Ïô∏Ï∂úÌïòÎäî Í≤ÉÎèÑ ÎààÏπòÎ¥êÏïºÎèº</td>\n","      <td>Ï†ïÎßê ÎÑàÎ¨¥ÌïòÎÑ§Ïöî Í∞úÏù∏Ï†ÅÏù∏ ÏãúÍ∞ÑÏù∏Îç∞.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4123</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏóê Ïô∏Ï∂úÌïòÎ©¥ Ïïà ÎêòÎÇò</td>\n","      <td>ÏãúÍ∞ÑÏïàÏóêÎßå Ïò®Îã§Î©¥ Í∞ÄÎä•ÌïòÏ£†.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4124</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏóê ÏùÄÌñâ Í∞îÎã§ÏôÄÏïºÏßÄ</td>\n","      <td>Î≥º ÏùºÏù¥ ÏûàÎÇòÎ¥êÏöî.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4125</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏóî Í∑∏ÎÉ• Ïâ¨Í≥† Ïã∂Ïñ¥</td>\n","      <td>ÎßõÎÇúÍ±∞ ÎìúÏãúÍ≥† Ï°∞Í∏àÏù¥ÎùºÎèÑ Ïâ¨ÏÖîÏïº Ìï†ÌÖêÎç∞.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4126</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏù¥ÎùºÎèÑ ÎßàÏùå ÎÜìÍ≥† Ïâ¨Í≥† Ïã∂Ïñ¥</td>\n","      <td>ÎßõÎÇúÍ±∞ ÎìúÏãúÍ≥† Ï°∞Í∏àÏù¥ÎùºÎèÑ Ïâ¨ÏÖîÏïº Ìï†ÌÖêÎç∞.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7700</th>\n","      <td>Ïù¥Ï†ú Ï†êÏã¨ÏãúÍ∞ÑÏóêÎèÑ ÎÑàÏóêÍ≤å Ïπ¥ÌÜ°ÏùÑ Ìï† ÏàòÍ∞Ä ÏóÜÍµ¨ÎÇò.</td>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏóê Ìï† Ïàò ÏûàÎäî Îã§Î•∏ Í±∏ Ìï¥Î¥êÏöî.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8008</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏû†Íπê Í∑∏ÎÖÄÍ∞Ä Ï†ÄÏóêÍ≤å ÌñàÎçò ÎßêÎì§Ïù¥ Îñ†Ïò§Î•¥ÎÑ§~„Ö†„Ö†</td>\n","      <td>ÏÉùÍ∞ÅÏùÑ Ï†ëÏñ¥ÎëêÎäî Í≤ÉÎèÑ ÌïÑÏöîÌï¥Ïöî.</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>11002</th>\n","      <td>Ï†êÏã¨ÏãúÍ∞ÑÏùº ÌÖêÎç∞ Ïπ¥ÌÜ°Ïù¥ Ïïà ÏôÄ.</td>\n","      <td>Î®ºÏ†Ä Ïó∞ÎùΩÏùÑ Ìï¥Î≥¥Îäî Í±¥ Ïñ¥Îñ®ÍπåÏöî?</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9c721bb5-4d96-4ceb-990a-bb6ee25215bd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4122]='Ï†ïÎßê ÎÑàÎ¨¥ÌïòÎÑ§Ïöî Í∞úÏù∏Ï†ÅÏù∏ ÏãúÍ∞ÑÏù∏Îç∞.'"],"metadata":{"id":"uzYA10CR-uNp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4123]='ÏãúÍ∞ÑÏïàÏóêÎßå Ïò®Îã§Î©¥ Í∞ÄÎä•ÌïòÏ£†.'"],"metadata":{"id":"heLvDrEh-9qK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4119]='ÎßûÏïÑÏöî Ìï≠ÏÉÅ Í≥†ÎØºÏù¥ ÎêòÏ£†.'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3P_9PPaB-E-R","executionInfo":{"status":"ok","timestamp":1670289161420,"user_tz":-540,"elapsed":272,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"2d624e7d-e48b-4f3c-db8c-8a092532e964"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4119]='ÎßûÏïÑÏöî Ìï≠ÏÉÅ Í≥†ÎØºÏù¥ÎêòÏ£†.'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mSGhspDm-mGP","executionInfo":{"status":"ok","timestamp":1670288947077,"user_tz":-540,"elapsed":260,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"dac00148-93a3-4e7b-f0c1-f6bce9140d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[4120]='Ï£ºÎ≥Ä Î∂ÑÎì§Ïùò ÏñòÍ∏∞Î•º Îì§Ïñ¥Î≥¥ÎäîÍ±¥ Ïñ¥Îñ®ÍπåÏöî?'"],"metadata":{"id":"4GUWmaej-dtv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[3311]='ÎÇ†Ïî®ÎèÑ Ï∂îÏö¥Îç∞ Îú®ÎÅàÌïú Íµ≠Î¨º ÎìúÏÑ∏Ïöî!'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-TZE8eN-MdY","executionInfo":{"status":"ok","timestamp":1670288845870,"user_tz":-540,"elapsed":251,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"2dcee5fb-bb22-4f13-84a4-db7263c4559b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data.A.loc[808]='Í∑∏Îü¥Î¶¨Í∞ÄÏöî ÌôïÏù∏Ìï¥Î≥¥ÏÑ∏Ïöî.'"],"metadata":{"id":"4kE1Pa5k3PEU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670288758962,"user_tz":-540,"elapsed":251,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"dd8f74ce-fdb1-459b-ea2a-d19cbd443a3f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","source":["Chatbot_Data=Chatbot_Data.copy()"],"metadata":{"id":"7C1kRZjG0PlL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.to_csv('chatbotdata.csv',encoding='cp949')"],"metadata":{"id":"f0o6c-570xLU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.A.loc[3691]='Ï´ëÍ∏ãÏù¥ÏóêÏöî.'"],"metadata":{"id":"ho4jMcd0zeU0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')"],"metadata":{"id":"o1ZqGb2_BPrT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n","#ÏúàÎèÑÏö∞ ÌôòÍ≤ΩÏóêÏÑú num_workers Îäî Î¨¥Ï°∞Í±¥ 0ÏúºÎ°ú ÏßÄÏ†ï, Î¶¨ÎàÖÏä§ÏóêÏÑúÎäî 2\n","train_dataloader = DataLoader(train_set, batch_size=32, num_workers=2, shuffle=True, collate_fn=collate_batch,)"],"metadata":{"id":"LADrzGWw4S_R","executionInfo":{"status":"ok","timestamp":1670390539701,"user_tz":-540,"elapsed":277,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["model.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mElEmpnS4S83","executionInfo":{"status":"ok","timestamp":1670390542123,"user_tz":-540,"elapsed":7,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}},"outputId":"cd12f575-880f-4ef0-9092-cd5c0cfeeae4"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(51200, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=51200, bias=False)\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["Chatbot_Data.drop(['Unnamed: 0','Íµ¨Î∂Ñ'],axis=1,inplace=True)"],"metadata":{"id":"D3VohQPtBFST","executionInfo":{"status":"ok","timestamp":1670390329809,"user_tz":-540,"elapsed":257,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.rename(columns = {'Ïú†Ï†Ä' : 'Q','Ï±óÎ¥á':'A'}, inplace = True)"],"metadata":{"id":"eM0n29TQBbsb","executionInfo":{"status":"ok","timestamp":1670390416961,"user_tz":-540,"elapsed":305,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["Chatbot_Data.to_csv('datset.csv',encoding='cp949')"],"metadata":{"id":"hmAVJjDWBw7J","executionInfo":{"status":"ok","timestamp":1670390448106,"user_tz":-540,"elapsed":252,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["learning_rate = 3e-5\n","criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","epoch = 10\n","Sneg = -1e18"],"metadata":{"id":"Nh9gnnTG5GKF","executionInfo":{"status":"ok","timestamp":1670390549322,"user_tz":-540,"elapsed":259,"user":{"displayName":"Î∞ïÏãúÌò∏","userId":"04591515150809458724"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()"],"metadata":{"id":"VxFluYy186Uj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print (\"start\")\n","for epoch in range(epoch):\n","    for batch_idx, samples in enumerate(train_dataloader):\n","        optimizer.zero_grad()\n","        token_ids, mask, label = samples\n","        out = model(token_ids)\n","        out = out.logits      #Returns a new tensor with the logit of the elements of input\n","        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n","        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n","        loss = criterion(mask_out.transpose(2, 1), label)\n","        # ÌèâÍ∑† loss ÎßåÎì§Í∏∞ avg_loss[0] / avg_loss[1] <- loss Ï†ïÍ∑úÌôî\n","        avg_loss = loss.sum() / mask.sum()\n","        avg_loss.backward()\n","        # ÌïôÏäµ ÎÅù\n","        optimizer.step()\n","print (\"end\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ed7rniu5GH5","outputId":"e3685b23-ffd4-454a-fdc3-277f522f4cc4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["start\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n","<ipython-input-10-495d11317178>:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n","  return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n"]}]},{"cell_type":"code","source":["with torch.no_grad():\n","    while 1:\n","        q = input(\"user > \").strip()\n","        if q == \"quit\":\n","            break\n","        a = \"\"\n","        while 1:\n","            input_ids = torch.LongTensor(koGPT2_TOKENIZER.encode(Q_TKN + q  + A_TKN + a)).unsqueeze(dim=0)\n","            pred = model(input_ids)\n","            pred = pred.logits\n","            gen = koGPT2_TOKENIZER.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().numpy().tolist())[-1]\n","            if gen == EOS:\n","                break\n","            a += gen.replace(\"‚ñÅ\", \" \")\n","        print(\"Chatbot > {}\".format(a.strip()))"],"metadata":{"id":"2Xo-3vp27lwg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["PATH = ''"],"metadata":{"id":"NB2si4tGsDgP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model,PATH+'save_model')"],"metadata":{"id":"JhXQx6fA7loY"},"execution_count":null,"outputs":[]}]}